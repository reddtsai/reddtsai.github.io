[{"content":"Redis 已被廣泛的運用在快取機制上，但是如果想查找符合條件的資料，或是某個範圍的資料時，除了用 scan 一個一個查找符合的資料，有沒有更好的方法？\nSorted Sets Redis 有序集合是由 score 和 member 所組成，score 用來排序可重複，member 是個鍵值不可重複，來看看官方的範例：\n這個範例 score 指的是年齡，member是姓名，這是個由年齡排序的集合。\n   score member     33 小明   38 小張   38 老王   40 大雄    ZADD 這裡介紹 ZADD 命令來添加有序集合的元素。\n1 2 3  ZADD AGEINDEX 38 \u0026#34;老王\u0026#34; ZADD AGEINDEX 40 \u0026#34;大雄\u0026#34; ZADD AGEINDEX 38 \u0026#34;小張\u0026#34; 33 \u0026#34;小明\u0026#34;   Redis 2.4 版後才可使用一次加入多個元素 命令選項(options)：\n XX：更新已存在元素，不會新增元素。 NX：新增元素，不會更新已存在元素。 CH：回覆命令執行後，元素被更新和新增數量。 INCR：增加元素 score。  1  ZADD AGEINDEX XX 34 \u0026#34;小美\u0026#34;   Redis 3.0.2 版後才可使用 options ZRANGE Redis 有序集合順序是由小到大，第一個位置是 0，第二個位置是 1，\u0026hellip;，-1 是倒數第一，-2 是倒數第二，\u0026hellip;。\n查找倒數第二個元素：\n1  ZRANGE AGEINDEX -2 -2   查找第二到第三的元素：\n1  ZRANGE AGEINDEX 1 2   由大至小排序可使用 ZREVRANGE ZRANGEBYSCORE ZRANGEBYSCORE 是透過 score 來查找元素，例如例出 30 歲到 40 歲的成員：\n1  ZRANGEBYSCORE AGEINDEX 30 40   例出 30 歲以上到 40 歲的成員：\n1  ZRANGEBYSCORE AGEINDEX (30 40   Reference Redis sorted Sets\n","description":"how to use Redis sorted sets","id":0,"section":"posts","tags":["Redis"],"title":"Redis 有序集合","uri":"https://reddtsai.github.io/zh/posts/redis_index/"},{"content":"1  git clone   branch 1  git branch   1  git branch -a   1  git branch -d   checkout 1  git checkout   1  git checkout -b   1  git checkout --track   log 1  git log   1  git log --oneline -5   1  git reflog   revert 1  git revert   reset 1  git reset   ","description":"noted git command","id":1,"section":"posts","tags":["Git"],"title":"Git 常用指令","uri":"https://reddtsai.github.io/zh/posts/git/"},{"content":"因為工作上需要使用 Protocol Buffers 當作資料交換的結構，那麼就來看看 Protocol Buffers 有什麼過人之處。\n以下說明所使用的環境\nOS ：Mac\nGolang：1.14\nEditer：Visual Studio Code Protocol Buffers Protocol Buffers 是一種序列化資料結構，由 Google 設計維護，目前有二個版本 proto2 和 proto3，主打比其它資料結構更小、更容易使用。\nInsatll  安裝 protocol compiler： 1 2  brew install protobuf brew --version    安裝 protobuf runtime：\n因為我是使用 golang，所以安裝 golang 的 protobuf runtime。 1 2  go get -u -v github.com/golang/protobuf/proto go get -u -v github.com/golang/protobuf/protoc-gen-go   設定環境變數\n1  sudo cp $(gopath)/bin/protoc-gen-go /usr/local/bin/     .proto 安裝完 Protocol Buffers 後，接著建立一個 user.proto，Protocol Buffers 定義檔的副檔名為 .proto。\n1 2 3  mkdir goprotobuf/model cd goprotobuf/model touch user.proto   user.proto\n1 2 3 4 5 6 7 8 9 10 11 12  syntax = \u0026#34;proto3\u0026#34;; package protomvc; option go_package = \u0026#34;.;model\u0026#34;; message user { int64 id = 1; string name = 2; string email = 3; string addr = 4; string phone = 5; }   可以看到 user.proto 的內容是有逹到 Google 所宣稱的容易簡單，其它 message type 可參考available wire types。\n.pb.go 當定義好 Protocol Buffers 資料傳輸結構後，接著將 user.proto 轉成 go struct，加入我們的 go package，透過 protocol compiler 來產生 user.pb.go。\n1  protoc --go_out=. *.proto   user.pb.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  // ~~~~ 略  type User struct { state protoimpl.MessageState sizeCache protoimpl.SizeCache unknownFields protoimpl.UnknownFields Id int64 `protobuf:\u0026#34;varint,1,opt,name=id,proto3\u0026#34; json:\u0026#34;id,omitempty\u0026#34;` Name string `protobuf:\u0026#34;bytes,2,opt,name=name,proto3\u0026#34; json:\u0026#34;name,omitempty\u0026#34;` Email string `protobuf:\u0026#34;bytes,3,opt,name=email,proto3\u0026#34; json:\u0026#34;email,omitempty\u0026#34;` Addr string `protobuf:\u0026#34;bytes,4,opt,name=addr,proto3\u0026#34; json:\u0026#34;addr,omitempty\u0026#34;` Phone string `protobuf:\u0026#34;bytes,5,opt,name=phone,proto3\u0026#34; json:\u0026#34;phone,omitempty\u0026#34;` } // ~~~~略   user.pb.go 的內容 是由 protocol compiler 所自動生成，請不要直接修改。 Marshal/Unmarshal 接下來建立一個 user 資料，然後產生 Protocol Buffers 序列資料，範例如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  func main() { user := \u0026amp;model.User{ Id: 1, Name: \u0026#34;john\u0026#34;, Email: \u0026#34;john@gmail.com\u0026#34;, Addr: \u0026#34;taipei\u0026#34;, Phone: \u0026#34;0212348765\u0026#34;, } buf, err := proto.Marshal(user) if err != nil { fmt.Println(err) } fmt.Println(buf) newUser := \u0026amp;model.User{} err = proto.Unmarshal(buf, newUser) if err != nil { fmt.Println(err) } fmt.Println(newUser) }   Polymorphism 接著說說 Protocol Buffers 的進階用法，例如你回應內容可能會有多種類型，Protocol Buffers 也提供了 any 的類型，比如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  syntax = \u0026#34;proto3\u0026#34;; package model; import \u0026#34;google/protobuf/any.proto\u0026#34;; option go_package = \u0026#34;.;model\u0026#34;; message body1 { string name = 1; } message body2 { int age = 1; } message Response { google.protobuf.Any message = 2; }   Protocol Buffers any 在 golang 的方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  import ( \u0026#34;github.com/golang/protobuf/ptypes\u0026#34; \u0026#34;google.golang.org/protobuf/proto\u0026#34; ) func main() { body := \u0026amp;model.body1{ Name: \u0026#34;redd1\u0026#34;, } m, err := ptypes.MarshalAny(body) if err != nil { fmt.Println(err) } fmt.Println(m.TypeUrl) }   UnmarshalAny 需先判斷資料的 TypeUrl，在使用相對定義結構來反序列。\nCap 最後看看 Google 宣稱的容量比較小，以下的範列 Protocol Buffers 容量 44，JSON 容量 96。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  func main() { user := \u0026amp;model.User{ Id: 1, Name: \u0026#34;john\u0026#34;, Email: \u0026#34;john@gmail.com\u0026#34;, Addr: \u0026#34;taipei\u0026#34;, Phone: \u0026#34;0212348765\u0026#34;, } bufProto, err := proto.Marshal(user) if err != nil { fmt.Println(err) } bufJson, err := json.Marshal(user) if err != nil { fmt.Println(err) } fmt.Println(cap(bufProto)) fmt.Println(cap(bufJson)) }   Reference Protocol Buffers\ngolang protobuf\n","description":"how to use protocol buffers with go","id":2,"section":"posts","tags":["Go"],"title":"使用 Protocol Buffers 結構化資料","uri":"https://reddtsai.github.io/zh/posts/go_protobuf/"},{"content":"Odds(賠率) 假設籃球A隊和B隊他們的對戰記錄如下表：\n   對戰 A B     1 勝 負   2 勝 負   3 勝 負   4 負 勝   5 勝 負   6 勝 負   7 勝 負   8 勝 負   9 負 勝   10 勝 負    籃球比賽的結果只有勝跟負(2-way)，當不考慮其它因素，那麼勝率的倒數就是它的賠率。\n A隊\n贏了8場，勝率80%，賠率為 ${1 \\over 0.8} = 1.25$，如果你投注100，獲勝時可贏得25。 B隊\n贏了2場，勝率20%，賠率為 ${1 \\over 0.2} = 5$，如果你投注100，獲勝時可贏得400。  賠率的觀念就介紹到這，想了解更多可進到台灣運彩官網，可以看到各個隊伍的數據，實際賠率會由這些數據來計算。\nMargin(利潤) 比賽賠率計算，除了隊伍的資訊因素還保含了莊家的利潤(margin)，以剛剛的賠率為例，不包含利潤的公式：\n$$1 = {{1 \\over Odds-A} + {1 \\over Odds-B}}$$\n假設莊家想獲得總投注5%的利潤，那麼計算公式就會變成這樣：\n$$1.05 = {{1 \\over Odds-A} + {1 \\over Odds-B}}$$\nReference 台灣運彩\ncalculator\n","description":"籃球賠率計算","id":3,"section":"posts","tags":["Margin"],"title":"認識運動彩卷賠率","uri":"https://reddtsai.github.io/zh/posts/bet_margin/"},{"content":"Golang 官方在 1.11 版推出了 Go modules，讓開發者透過 go mod 來管理 project 或 package 中所使用的套件。\nInit 假設今天需要建立一個 RESTful 專案，內容如下：\n1 2 3  mkdir api cd api touch main.go   main.go\n1 2 3 4 5 6 7 8 9 10 11 12 13  package main import \u0026#34;github.com/gin-gonic/gin\u0026#34; func main(){ r := gin.Default() r.GET(\u0026#34;/ping\u0026#34;, func(c *gin.Context) { c.JSON(200, gin.H{ \u0026#34;message\u0026#34;: \u0026#34;pong\u0026#34;, }) }) r.Run() }   可以看到這裡有使用 Gin 這個套件，接下來透過 go mod 來添加這個套件，首先需初始 go modules：\n1  go mod init api   完成後會產生一個 modules 設定檔 go.mod，接下來當你執行 build、run、test 等命令，modules 會自動幫你加入相依套件，當然你還是可以透過 get 來取得套件，下方是這次 go.mod 的內容：\n1 2 3 4 5  module api go 1.14 require github.com/gin-gonic/gin v1.6.3 // indirect   Golang 提供一個環境變數 GO111MODULE 來控制是否啟用 go modules Get 可使用以下方法來取得或更新相依套件：\n1 2  # 透過 go.mod 來取得或更新相依套件 go mod download   1 2  # 使用指令來取得或更新相依套件 go get [-u]   如果有使用到私有套件，需要在 go 環境變數 GOPRIVATE 加入你的私有套件網域名，另外，你會需要透過登入或SSH來取得私有套件的權限。例設一個 private gitlab 套件，gitlab.com/name/repo，設定如下：\n1  go env -w GOPRIVATE=gitlab.com/name   List 列出目前使用到的相依套件：\n1  go list -m all   Clean 清除未使用的套件，執行前最好先清除暫存。\ngo clean go mod tidy Reference Go modules\n","description":"using go modules","id":4,"section":"posts","tags":["Go"],"title":"Golang 套件管理系統 mod","uri":"https://reddtsai.github.io/zh/posts/go_mod/"},{"content":"身為一個加密貨幣交易所的後台工程師，記錄一下我如何與比特幣(Bitcoin)一起工作。\nBitcoin 比特幣(Bitcoin)是一種基於去中心化，採用點對點網路與共識主動性，開放原始碼，以區塊鏈作為底層技術的加密貨幣，目前由社群共同維護這個協議(BIP)。而比特幣何運作主要由四個功能組合而成：\n 錢包(wallet) 區塊鏈(blockchain) 節點(node) 礦工(miner)  Exchange 加密貨幣交易所是一種中心化，提供兌換和投資加密貨幣的服務，把加密貨幣視為金融商品。以比特幣兌換服務來說，A 想用 US$9000 買一顆比特幣，當 A 支付完 US$9000，透過交易所錢包建立一個交易，傳至一個比特幣節，然後等到礦工確認完這個交易，A 的比特幣錢會收到一顆比特幣。從這個說明可看出，交易所通常只需要使用比特幣錢包和節點的功能。後續會介紹怎麼在交易實作這二個功能。\nReference 參考來源\nbitcoin\n","description":"Introduce how to reference bitcoin in the exchange.","id":5,"section":"posts","tags":["Bitcoin","Exchange"],"title":"加密貨幣交易所：Bitcoin Implementation 1","uri":"https://reddtsai.github.io/zh/posts/btc_summary/"},{"content":"第一次發 Golang 的文章，當然要來個 hello world 作為開場。\n環境\nOS ：Mac\nGolang：1.14\nEditer：Visual Studio Code Installation 安裝 Go。\n1 2 3  brew install go@1.14 go version   Stable versions First Package 環境準備就緒後，來建立第一個 Go Project。\n1 2 3 4  mkdir hello cd hello touch hello.go code .   example. hello.go\n1 2 3 4 5 6 7  package main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;hello world\u0026#34;) }   來看到 hello.go 的內容，作個基本認識：\n package  命名(naming)，一個 .go 檔，除了 main 之外，第一步是替 package 命名，請先參考 package names 瞭解命名規則，必免在引用 package 時產生困擾。 空間(space)，相同目錄中的 .go 檔，藉由 package 來組織和編譯，就像其它語言 namespace 的功用。   import  導入 local 或 remote 套件。   function  名稱(name)，func name() 輸入(input)，func(input) 輸出(output)，func() (output)    執行 hello.go 顯示 hello world\n1  go run hello.go   Modules 接著是套件管理，從 Go 1.11 開始有了 Go Modules，這裡只要先有個觀念，不論 local 或 remote 套件請使用 Go Modules 來管理。\nCLI - go mod Testing 當 Package 完成後，別忘了 go 有個很好用的 test framework。\nexample. hello_test.go\n1 2 3 4 5 6 7 8 9  package main import ( \u0026#34;testing\u0026#34; ) func TestHello(t *testing.T) { t.Log(\u0026#34;hello world\u0026#34;) }   執行測試\n1  go test -v   Tour of Go 如果你是第一次學習程式，對 Go 毫無概念，可從線上 Tour 開始。\nTour of Go\nEditer 介紹一個免費且功能強大的程式碼編輯器 Visual Studio Code，讓你編輯專案更有效率。\n 下載安裝\n至官網下載最新的安裝程式，執行並安裝。 安裝 Go 擴充工具\n開啟 Visual Studio Code，移至 Extensions 頁面，安裝 Go。  Reference GO\n","description":"建立 golang 開發環境，進入第一個專案","id":6,"section":"posts","tags":["Go"],"title":"初次見面 Golang","uri":"https://reddtsai.github.io/zh/posts/go_hello/"},{"content":"在前後端分離的環境下，在前端需要和公司後台或第三方 API 溝通時，因為請求來自於不同網域、通訊協定或通訊埠時，而遇到跨來源資源共用(CORS)的問題。如果是在開發時遇到這個問題，可以利用開發環境請求代理來解決。\nAccess to XMLHttpRequest at \u0026lsquo;https://www.xxx.com/api' from origin \u0026lsquo;http://localhost:8080\u0026rsquo; has been blocked by CORS policy: No \u0026lsquo;Access-Control-Allow-Origin header is present on the requested resource. vue.config.js Vue 透過配置文件(vue.config.js)來設定開發環境請求代理。\n1 2 3 4 5 6 7  module.exports = { devServer: { proxy: { target: \u0026#39;http://localhost:8080\u0026#39; } } }   這會將任何未知請求代理到 http://localhost:8080。\n也可設定多組代理或使用 websocket。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  module.exports = { devServer: { proxy: { \u0026#39;/ws\u0026#39;: { target: \u0026#39;wss://localhost\u0026#39;, ws: true, changeOrigin: true }， \u0026#39;/api\u0026#39;: { target: \u0026#39;http://localhost:8080\u0026#39; } } } }   Reference Vue CLI devserver\n","description":"fix CORS policy issue by devServer","id":7,"section":"posts","tags":["Vue"],"title":"Vue 開發環境請求代理","uri":"https://reddtsai.github.io/zh/posts/vue_cors/"},{"content":"如果你跟我一樣習慣用 MVC 或是剛踏入前端的新手，需要一個 Front-end frameworks，請先參考下圖。\n假設你跟我一樣選擇 Vue.js，可以參考以下步驟來幫助你建立 Vue.js 的開發環境。\nInstallation 以下是為 Mac 安裝 Vue 開發環境的步驟。\n 安裝 Node.js 1  brew install node    安裝 Vue.js 1  npm install vue    安裝 Vue CLI 1  npm install -g @vue/cli     如果你不是要建立 Vue 專案，你也可以直接將 Vue.js 加入既有網頁中使用\n\u0026lt;script src=\u0026quot;https://cdn.jsdelivr.net/npm/vue/dist/vue.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; Creating Vue Project 環境準備就緒後，就可透過 Vue CLI 來建立一個 Vue Project。\n1  vue create hello-vue   接著會詢問專案設定，你可選用你慣用的功能項目。\n你也可以使用 Vue CLI UI 介面來建立專案。\n1  vue ui   試著執行剛建好的專案 hello-vue\n1 2  cd hello-vue npm run serve   可以看到 Vue 歡迎畫面(http://localhost:8080/)\nCode Editing 當環境和專案都準備就緒，介紹一個免費且功能強大的程式碼編輯器 Visual Studio Code，讓你編輯專案更有效率。\n 下載安裝\n至官網下載最新的安裝程式，執行並安裝。 安裝 Vue 擴充工具 Vetur\n開啟 Visual Studio Code，移至 Extensions 頁面，安裝 Vetur  Reference Vue.js\n","description":"建立 Vue 開發環境","id":8,"section":"posts","tags":["Vue"],"title":"初次見面 Vue","uri":"https://reddtsai.github.io/zh/posts/vue_hello/"},{"content":"介紹一個輕量級性能測試工具 wrk 給後端開發者，它可協助你瞭解 1.為什麼服務掛了?? 2.需不需要 Load Balance?? 3.API 的 QPS 多少?? 等等 \u0026hellip;，來看看怎麼作。\n環境\n Mac Nginx (Debian 9, Google 雲端平台) API (.NET Core 3.0, Google 雲端平台) SQL Server (Google 雲端平台)  Install 首先安裝 wrk，因為個人是使用 Mac 就透過 Homebrew 來安裝：\n1  brew install wrk   Test 準備好要測試的 API，使用 wrk 進行壓測：\nGET http://35.234.53.61/api/lotto649/109000035，它會回傳一段 Json\n1  wrk -t8 -c500 -d30s --latency http://35.234.53.61/api/lotto649/109000035   -c, \u0026ndash;connections：跟伺服器建立並保持的TCP連接數量\n-d, \u0026ndash;duration ：壓測時間 -t, \u0026ndash;threads ：開啟多少個線程進行壓測 -s, \u0026ndash;script ：Lua腳本路徑 -H, \u0026ndash;header ：添加 HTTP header\n\u0026ndash;latency ：列印延遲統計信息\n\u0026ndash;timeout ：timeout -v, \u0026ndash;version ：wrk的詳細版本信息 測試報告：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  Running 30s test @ http://35.234.53.61/api/lotto649/109000035 8 threads and 500 connections Thread Stats Avg Stdev Max +/- Stdev Latency 708.36ms 223.55ms 1.80s 83.41% Req/Sec 57.29 49.79 346.00 82.95% Latency Distribution 50% 707.45ms 75% 819.04ms 90% 878.19ms 99% 1.70s 10240 requests in 30.06s, 3.12MB read Socket errors: connect 251, read 0, write 0, timeout 0 Requests/sec: 340.64 Transfer/sec: 106.45KB   報告有幾個重點：\n 平均每秒處理(Requests/sec) 平均每秒流量(Transfer/sec) 發生錯誤數(Socket errors)  lua wrk 有提供自定義腳本，可用來客製測試方法和報告。例如需使用 POST 方法測試 API：\npost.lua\n1 2 3  wrk.method = \u0026#34;POST\u0026#34; wrk.body = \u0026#34;{ \u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;redd\u0026#34; }\u0026#34; wrk.headers[\u0026#34;Content-Type\u0026#34;] = \u0026#34;application/json\u0026#34;   Reference wrk\n","description":"使用 wrk 測試 API 的吞吐量","id":9,"section":"posts","tags":["Load"],"title":"API 性能測試","uri":"https://reddtsai.github.io/zh/posts/dotnet_wrkloadtest/"},{"content":"主流程式語言大多可以跨平台作業，但對 .NET 來說是個新鮮事，這次就來分享將 API 部署到 Linux。\nCreate a VM 首先請準備一台 Linux 主機，可參考快速建立 Compute Engine。\n這次範例是使用 Debian 9 Dependencies and Requirements 接著安裝 ASP.NET Core 環境依賴關係和要求：\n Install .Net Core 3.1  安裝前請先註冊 Microsoft 金鑰和套件摘要： 1 2 3 4 5 6 7 8  # 註冊微軟金鑰 wget -O- https://packages.microsoft.com/keys/microsoft.asc | gpg --dearmor \u0026gt; microsoft.asc.gpg sudo mv microsoft.asc.gpg /etc/apt/trusted.gpg.d/ # 註冊產品存儲庫 wget https://packages.microsoft.com/config/debian/9/prod.list sudo mv prod.list /etc/apt/sources.list.d/microsoft-prod.list sudo chown root:root /etc/apt/trusted.gpg.d/microsoft.asc.gpg sudo chown root:root /etc/apt/sources.list.d/microsoft-prod.list    透過套件管理(apt-get)安裝 .NET Core： 1 2 3 4 5 6  # Install apt-get enable SSL sudo apt-get update sudo apt-get install -y apt-transport-https # Install the .NET Core runtime sudo apt-get update sudo apt-get install aspnetcore-runtime-3.1      Install Nginx  安裝反向 Proxy 伺服器： 1  apt-get install -y nginx    設置站台：\n修改 /etc/nginx/sites-available/default 1 2 3 4 5 6 7 8 9 10 11 12 13 14  server { listen 80; server_name example.com *.example.com; location / { proxy_pass http://localhost:5000; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection keep-alive; proxy_set_header Host $host; proxy_cache_bypass $http_upgrade; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; } }    重新載入設定： 1  sudo nginx -s reload      Deploy your api\n請將你的 api 放置到這個位置 /var/www/your_api。 Monitor your api  新增服務：\n/etc/systemd/system/sample_api.service 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  [Unit] Description=.NET Web API running on Debian [Service] WorkingDirectory=/var/www/sample_api。 ExecStart=/usr/bin/dotnet /var/www/sample_api/sample_api.dll Restart=always # Restart service after 10 seconds if the dotnet service crashes: RestartSec=10 KillSignal=SIGINT SyslogIdentifier=dotnet-api User=www-data Environment=ASPNETCORE_ENVIRONMENT=Production Environment=DOTNET_PRINT_TELEMETRY_MESSAGE=false [Install] WantedBy=multi-user.target    啟動服務： 1 2  sudo systemctl enable kestrel-helloapp.service sudo systemctl start kestrel-helloapp.service       完成後，你可由瀏覽器或 curl 作個測試：\n1 2  curl http://localhost curl http://your ip   Deployment Script 建立自動化腳本 gce-startup.sh。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  # Install Stackdriver logging agent curl -sSO https://dl.google.com/cloudagents/install-logging-agent.sh sudo bash install-logging-agent.sh # Install apt-get enable SSL sudo apt-get -yq install apt-transport-https sudo apt-get -yq install git # Register Microsoft key and feed wget -O- https://packages.microsoft.com/keys/microsoft.asc | gpg --dearmor \u0026gt; microsoft.asc.gpg sudo mv microsoft.asc.gpg /etc/apt/trusted.gpg.d/ wget https://packages.microsoft.com/config/debian/9/prod.list sudo mv prod.list /etc/apt/sources.list.d/microsoft-prod.list 。。。   這次範例所製作的腳本，每次部署都會建立全新的 VM 來部署程式，但在容器的部署上，會由 Image 持續來更新 Container，有機會在另外說明。 Load Balance 最後來介紹一下如何建立負載平衡(Load Balance)，因為這次 Host 是使用 GEC，透過 GEC 執行個體群組和剛建立的自動化腳本就可快速完成，修改一下腳本 gce.sh：\n1 2 3 4 5 6 7 8 9 10 11 12  。。。 gcloud compute instance-groups managed create group-aspnet \\  --base-instance-name aspnet \\  --size 2 \\  --template tmp-aspnet-debian \\  --target-pool pool-aspnet gcloud compute forwarding-rules create lb-aspnet \\  --ports 80 \\  --region asia-east1 \\  --target-pool pool-aspnet   e.g.\nReference Sample Project\n.NET\n","description":"在 Linux 上使用 ASP.NET Core","id":10,"section":"posts","tags":["GCE","dotnet","Debian"],"title":"Linux + Nginx + .NET Core API","uri":"https://reddtsai.github.io/zh/posts/dotnet_hostingce/"},{"content":"隨著雲端時代的到來，讓軟體開發與雲端平台變得密不可分。雲端有那些好處？該選那個雲端供應商 AWS、Azure、GCP、阿里云？？網上有很多論述可供參考。當你要加入雲端時，千萬不要直接將公司的 Server 搬上雲端，因為很有可能讓公司發不出薪水。\nHow 那要如何加入雲端？我會建議你以下 Step：\n 認識雲端 架構規劃 選擇供應商 試算成本 申請預算 打統編報稅  架構規劃的部分，只有適合你的架構，沒有正確答案，建議先瞭解以下幾個雲端主流架構：\n Serverless\nGCP:App Engine\nAzure:Functions\nAWS:Lambda\nAliCloud:函数计算 VM\nGCP:Compute Engine\nAzure:VM\nAWS:EC2\nAliCloud:云服务器 Container\nGCP:Kubernetes Engine\nAzure:Kubernetes Service\nAWS:Elastic Kubernetes Service\nAliCloud:容器服务  ","description":"如何加入雲端？","id":11,"section":"posts","tags":["GCP"],"title":"快樂上雲端","uri":"https://reddtsai.github.io/zh/posts/gcp/"},{"content":"分享個人如何將雲端虛擬機器結合到開發工作中，例如，當專案需要二台主機，一台用來作使用者測試，另一台給未來營運使用，以下介紹個人的作法給大家參考。未來作持續更新部署(CI/CD)或自動擴展(Auto Scaling)也會使用這個自動化腳本。\nCreate a Compute Engine instance 透過 CLI 的方式來介紹如何建立一台虛擬機器，這次使用的是 Google Cloud 提供的虛擬機器 Compute Engine。\n請先準備好你的 Google 帳號和 SDK  設定 VM 所在區域 (Zone) 1 2  gcloud config set compute/zone [zone] gcloud config set compute/region [region]   東南亞可選擇新加坡，東北亞可選擇首爾。\nRegions and Zones  新增一台 VM (Compute Engine) 1  gcloud compute instances create [instance]   機器類型：虛擬化硬體規格。ex. \u0026ndash;machine-type=g1-small\n作業系統：Windows, Linux。ex. \u0026ndash;image-family=debian-9  設定防火墻 (Firewall)\nEnable port 80 for web site 1  gcloud compute firewall-rules create allow-80 --allow tcp:80    建立負載平衡 (Load balancing)\n如果你需要建立負載平衡，依照 GCP 說明，要使用叢集(cluster)來建立 VM(取代第二步)。 1 2 3 4 5 6 7  gcloud compute instance-templates create [template] gcloud compute target-pools create [pool] gcloud compute instance-groups managed create [group] \\  --base-instance-name [name] \\  --size 2 \\  --template [template] \\  --target-pool [pool]   負載平衡：\n1 2 3  gcloud compute forwarding-rules create [loadbalance] \\  --ports 80 \\  --target-pool [pool]     完成後，你可以試著透過 SSH 登入 VM：\n1  gcloud compute ssh [instance]   Create Deployment Script 接下來，將建立容器的動作，透過 shell script 製作成腳本。後續你可將這個腳本加入版本控制，持續更新部署。\n使用者測試環境，Create_SIT_GCE.sh。\n1 2 3 4 5 6 7 8 9  MY_INSTANCE_NAME=\u0026#34;sit-vm\u0026#34; ZONE=asia-east1-a gcloud compute instances create $MY_INSTANCE_NAME \\  --image-family=debian-9 \\  --image-project=debian-cloud \\  --machine-type=g1-small \\  --scopes userinfo-email,cloud-platform \\  --zone $ZONE \\   營運環境，Create_PRD_GCE.sh。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  gcloud config set compute/zone asia-east1-a gcloud config set compute/region asia-east1 gcloud compute instance-templates create prd-template \\  --image-family=debian-9 \\  --image-project=debian-cloud \\  --machine-type=g1-small \\  --scopes userinfo-email,cloud-platform gcloud compute target-pools create prd-pool gcloud compute instance-groups managed create prd-group \\  --base-instance-name prd \\  --size 2 \\  --template prd-template \\  --target-pool prd-pool gcloud compute forwarding-rules create lb-prd \\  --ports 80 \\  --target-pool prd-pool   Clean up Compute Engine instance 不需要時清除 VM，避免計費問題。\n1 2 3 4 5 6  gcloud compute forwarding-rules delete [loadbalance] gcloud compute instance-groups managed delete [group] gcloud compute target-pools delete [pool] gcloud compute instance-templates delete [template] gcloud compute instances delete [instance] gcloud compute firewall-rules delete allow-80   Reference Compute Engine\n","description":"Write a script to create Compute Engine","id":12,"section":"posts","tags":["GCE"],"title":"快速建立 Compute Engine","uri":"https://reddtsai.github.io/zh/posts/gcp_computeengine/"},{"content":"至從開始使用 dotnet core 後，個人的開發方式也從 Visual Studio on Windows，轉換為 Visual Studio Code on Mac，轉變的過程有很多值得記錄。例如最近開發上需要安裝一個 dotnet 工具，如果是用 Visual Studio，會交由擴充管理員來安裝工具，那在沒有 Visual Studio 的協助下呢？這裡會介紹如何使用 CLI 來安裝 dotnet-ef。\nRequirements 首先準備好環境，以我為例：\n macOS 10.15 .NET Core 3.1  環境確認後，透過以下指令，列出已安裝的 dotnet tool。\n1 2  dotnet tool list dotnet tool list -g   g：全域 Install 透過 dotnet CLI 來安裝工具，這裡介紹安裝 dotnet-ef 工具到全域或本地。\n Global 1  dotnet tool install dotnet-ef -g    Local\n安裝本地工具，需要定義 manifest file。首先準備好 dotnet project，在專案下執行以下命令，它會產生一個 dotnet-tools.json 記錄本地工具。 1 2  dotnet new tool-manifest dotnet tool install   .config/dotnet-tools.json\n1 2 3 4 5 6 7 8 9 10 11 12  { \u0026#34;version\u0026#34;: 1, \u0026#34;isRoot\u0026#34;: true, \u0026#34;tools\u0026#34;: { \u0026#34;dotnet-ef\u0026#34;: { \u0026#34;version\u0026#34;: \u0026#34;3.1.3\u0026#34;, \u0026#34;commands\u0026#34;: [ \u0026#34;dotnet-ef\u0026#34; ] } } }     Update 更新 dotnet tool，一樣分為全域和本地，如下示範：\n Global 1  dotnet tool update -g dotnet-ef    Local 1  dotnet tool update dotnet-ef     Uninstall 卸載已安裝的工具：\n Global 1  dotnet tool uninstall -g dotnet-ef    Local 1  dotnet tool uninstall dotnet-ef     Reference .NET Core tools\n","description":"使用 CLI 來安裝 dotnet-ef","id":13,"section":"posts","tags":["dotnet"],"title":"在 Mac 上安裝 dotnet tool","uri":"https://reddtsai.github.io/zh/posts/dotnet_tool/"},{"content":"開發 .NET 應用程式在處理資料時，都會建立模型類別(Model)，特別像是 MVC 的專案，而當資料要儲存到資料庫時，資料庫需要產生對映 Schema 來儲存。這時千萬別馬上開始，先瞭解幾個專有名詞 code first、model first、database first，然後，再利用自動生成工具來減少你的工作，工具像是 PMC Tool - Migrations、POCO Entity \u0026hellip;。\n不過這些工具，個人覺得在 mac 上，使用起來不是很順手，個人較習慣使用 CLI Tool 的方式，接下來用個實例說明反向工程，如何用 MySQL Schema 生成模型類別到專案中。\n我所使用的環境：\n Mac Visual Studio Code dotnet core 3.0 dotnet-ef Makefile  Installing 請先建立好你的 dotnet project，然後確認已安裝：\n CLI Tool\n安裝 dotnet-ef 工具，用來作模型移轉。 1  dotnet tool install --global dotnet-ef    Database Provider\n我所使用的是 MySQL，需安裝 MySql 資料庫提供者。 1  dotnet add package Pomelo.EntityFrameworkCore.MySql    PROVIDER\n  EntityFrameworkCore.Design\n如果你是使用 .NET Core 2.1 以上的版本，.NET Core SDK 已包含 Design，可跳過這一步。 1  dotnet add package Microsoft.EntityFrameworkCore.Design     Scaffold 當資料庫和工具準備完成，透過 dbcontext scaffold 指令來進行反向工程，它會讀取資料庫的資訊，像 tables, columns, constraints, and indexes \u0026hellip;，然後生成 DbContext.cs 和 Models.cs。\n1  dotnet ef dbcontext scaffold \u0026#34;server=127.0.0.1;port=3306;user=root;password=pwd;database=db\u0026#34; Pomelo.EntityFrameworkCore.MySql   Script 最後，建立 makefile 腳本持續更新模型\n1 2 3 4 5 6  efScaffold: dotnet ef dbcontext scaffold \u0026#34;server=127.0.0.1;port=3306;user=root;password=pwd;database=db\u0026#34; \\  Pomelo.EntityFrameworkCore.MySql \\  -o Repositories/Entities \\  --context-dir Repositories -c LotteryContext \\  -p src -f   Reference Side Project\nReverse Engineering\n","description":"利用 dotnet-ef 實作 DB 反向工程","id":14,"section":"posts","tags":["EF"],"title":"用 dotnet ef 工具，從 MySQL 自動生成 Model.cs","uri":"https://reddtsai.github.io/zh/posts/dotnet_efreverse/"},{"content":"後端工程師的工作中很常需要一個常駐程式，幫我們處理非即時的工作或例行性的排程工作，在 Windows Sever 中有大家熟悉的服務和工作排程，那 Unix-Like Server 呢？？你可能常常聽到 Daemon (守護)，很難跟 Service 聯想在一起，在 Unix-Like 系統中常會將背景程式稱作 Daemon。接下來透過工作上的實例來說說這個 Daemon。這個工作需求是要在 Debian 下安裝 cloud sql proxy，然後，要它在背景執行，開機時自己啟動，在這裡作個記錄 。\nSystemd - 服務管理機制 這次工作所使用的系統為 Debian，在 Debian 及其它 Unix-Like 系統中，都有個服務管理機制 systemd，透過這個機制來啟動、關閉與觀察系統服務或你所自定的服務。\n可分為幾個類型如下：\n .service 一般服務 .socket 程序資料交換 .target 執行環境 .mount 檔案系統掛載 .automount 檔案系統掛載 .path 偵測特定檔案或目錄 .timer 循環執行   存放位置\n/usr/lib/systemd/system/：啟動腳本設定檔\n/run/systemd/system/：執行過程中所產生的服務腳本\n/etc/systemd/system/：管理員所建立的執行腳本\n 那要怎麼將 cloud sql proxy 加入 systemd 中？？\n本次會使用一般服務 cloud_sql_proxy.service，將檔案放入啟動位置 /etc/systemd/system/。\n範例 /etc/systemd/system/cloud_sql_proxy.service\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  # 服務解釋、相依性 [Unit] Description=Connecting MySQL Client from Compute Engine using the Cloud SQL Proxy Requires=networking.service After=networking.service # 服務執行的指令參數 [Service] WorkingDirectory=/usr/local/bin ExecStart=/usr/local/bin/cloud_sql_proxy -dir=/var/run/cloud-sql-proxy -instances=redd-side-project:asia-east1:db-mysql-001=tcp:3306 Restart=always StandardOutput=journal User=root # 要掛載哪個 target 底下 [Install] WantedBy=multi-user.target   Systemctl - 服務管理指令 初步認識 systemd 後，還需認識一個管理程式 systemctl，主要會透過 systemctl 的指令來處理我們的服務。\n接下來透過 systemctl 來操控 cloud_sql_proxy.service。\n啟用/停用，下次開機生效\n1 2  sudo systemctl enable cloud-sql-proxy.service sudo systemctl disable cloud-sql-proxy.service   立刻啟動/關閉\n1 2  sudo systemctl start cloud-sql-proxy.service sudo systemctl stop cloud-sql-proxy.service   列出狀態\n1  sudo systemctl status cloud-sql-proxy.service   常用指令\n1 2 3 4 5 6 7 8 9 10  -- 重新載入設定檔 sudo systemctl daemon-reload -- 列出所有啟動的 unit sudo systemctl -- 列出所有 .service sudo systemctl list-units --type=service --all -- 列出所有 cpu 為名 .service sudo systemctl list-units --type=service --all | grep cpu -- 列出相依 sudo systemctl list-dependencies   到這邊就完成了這次的工作任務，將 cloud_sql_proxy.service 在背景執行及開機時自己啟動。\nTimer - 排程 一開始除了服務，還有提到例行性的排程工作，那要怎麼使服務定期執行某個工作？？現學現賣，拿 systemd.timer 來作個實例(大多數的資訊都會用 crond 來定期處理服務😸😸)。\n我希望每日執行一次我的 APP\n 啟動系統 timer.target app.service 你的工作 app.timer 你的排程(與你的工作同名)\n範例 side project\n/etc/systemd/system/app.service  1 2 3 4 5 6 7  [Unit] Description=taiwan lottery scarper [Service] WorkingDirectory=/opt/app/gce/env/bin ExecStart=/opt/app/gce/env/bi/python /opt/app/app.py [Install] WantedBy=multi-user.target   /etc/systemd/system/app.timer\n1 2 3 4 5 6 7 8 9  [Unit] Description=scheduling taiwan lottery scarper [Timer] OnActiveSec=1m OnCalendar=Sun *-*-* 01:00:00 Persistent=true Unit=lotto-scraper.service [Install] WantedBy=multi-user.target   Reference 鳥哥\n","description":"將 cloud sql proxy 加入系統服務","id":15,"section":"posts","tags":["Daemon","Debian"],"title":"系統服務 In Debian","uri":"https://reddtsai.github.io/zh/posts/os_debiandaemon/"},{"content":"不論公司 project 或個人 side project，都會遇到資料儲存的需求，這時可能就是\n 求 DBA 自己安裝 向 Infra 申請 開始學 SQL Google  Why Cloud SQl 我為什麼選擇 Cloud SQl？原因只有一個，就是快\n 安裝快 上手快 擴展快 運維快  這裡會用 GCP 提供的 Cloud SQl 來說明，當然也可以選擇 AWS、Azure、阿里雲的產品。\nInstall MySQL 安裝快，只需幾分鐘就能建立一台 DB。開始安裝前你需要先有：\n 啟用 Google Cloud (你需要一組 Google 帳戶和一張信用卡) 安裝 cloud SDK  1  brew cask install google-cloud-sdk   安裝 DB 只需開啟終端機，執行下段命令。\n1  gcloud sql instances create [INSTANCE_NAME] --tier=[MACHINE_TYPE] --region=[REGION]      INSTANCE_NAME：命名你的 Database instance。\n  MACHINE_TYPE：Database 規格。Price\n  REGION：Instance 存放位置。Region\nCreating instances 說明\n   另外，你不習慣冷冰冰的命令，GCP 也提供 UI 介面讓你設定。\nConnection 上手快，你可快速連至 cloud database，官方提供多種方式及各程式語言的完整範例說明，減少你摸索的時間。\n這裡介紹透過 cloud sql proxy 快速連到剛建立的 DB。首先，安裝 cloud sql proxy\n1 2  gcloud components install cloud_sql_proxy ./cloud_sql_proxy -instances=\u0026lt;INSTANCE_CONNECTION_NAME\u0026gt;=tcp:3306   如下圖所示，你可以找到 INSTANCE_CONNECTION_NAME\n再來使用 MySQL workbench 來作個本機連線測試，如果你還沒安裝，請先透過以下命令來安裝。\n1  brew cask install mysqlworkbench   Replication 擴展快、運維快，當你初步認識 SQL 後，再進階就是效能跟穏定，最長聽到的就是 HA(high availability)，而在 cloud sql 你也只需要作簡單的設定來逹成 HA，讓你的 DB 擁有備援。\n另一個例子，在 cloud sql 新增一個讀取位置，分散流量來提升效能。\nReference 本次實作的費用\ncloud sql for mysql\n","description":"Cloud SQl for MySQL on Google Cloud Platform","id":16,"section":"posts","tags":["MySQL"],"title":"在雲上使用 MySQL","uri":"https://reddtsai.github.io/zh/posts/gcp_mysql/"},{"content":"身為一位軟體工程師怎麼可以沒有 Blog，再加上工程師最愛挖洞給自己跳，所以一定要自己架Blog😭😭😭。這裡跟大家介紹個靜態網站生成引擎 HUGO，接著透過 HUGO 來建立一個美美又免費的Blog。\nAbout Hugo HUGO 是由 go 所編寫的靜態網站生成器，最初由 Steve Francia 創立，以開源專案方式持續更新。Hugo 提供將資料檔案、i18n 包、組態、布局模板、靜態檔案，以及用 Markdown 編寫的內容，生成一個完整的靜態網站。\nCreate a Hugo site 以下說明你可能需要一點程式基楚，這裡會使用 mac os 來作說明。(個人是使用蘋果筆電😅😅)\n1.安裝 Hugo 使用 homebrew 安裝 Hugo，在終端機中輸入\n1  brew install hugo   驗証安裝成功，確認 hugo 版本。\n1  hugo version   2.產生新網站 透過 new 命令來產生一個新站台，在終端機中操作\ncd YourWorkSpace hugo new site myBlog 3.美化網站 加入外觀主題到剛建立好的網站，在這挑選一個外觀主題。\n我用 Ananke 來作說明，在終端機中操作\n1 2 3  cd myBlog git init git submodule add https://github.com/budparr/gohugo-theme-ananke.git themes/ananke   設定主題\n1  echo \u0026#39;theme = \u0026#34;ananke\u0026#34;\u0026#39; \u0026gt;\u0026gt; config.toml   4.加入文章 使用 new 命令來產生一篇文章，在終端機中操作\n1  hugo new posts/my-first-post.md   你可以用 markdown 編輯內容。\n5.啟動網站 啟動你的 Blog\n1  hugo server -D   打開瀏覽器 http://localhost:1313/\n參考來源 謝謝 HUGO\n","description":"透過HUGO建立Blog","id":17,"section":"posts","tags":["Hugo"],"title":"建立免費的個人博客 By HUGO","uri":"https://reddtsai.github.io/zh/posts/hugo_hello/"},{"content":"Hello，大家好我是Redd，是位網路後端軟體工程師(Internet Backend Engineer)，在此一邊記錄並與大家分享自己的工作經驗。\n","description":"about page of Redd's side project","id":18,"section":"","tags":null,"title":"About","uri":"https://reddtsai.github.io/zh/about/"},{"content":"Elastic 提供一個強大的 UI 介面 Kibana，透過它能更有效的分享與呈現 Elasticsearch 中的數據，接下來會以本身使用的案例，來介紹如何使用 Kibana。\n 版本\n Kibana 6\n安裝請參考下一篇文章CentOS 7 如何安裝 Kibana   Discover Page 數據探索功能，使用 Elasticsearch Index、Time Range 和 Query DSL 過濾搜索，顯示數據計數和內䆟\n 注意\n如果遇到 no cached mapping for this field\n試著在 Management，Refresh field list\n Dashboard Page 儀表版功能，Kibana 提供多樣視覺化圖表，儀表版可幫助你收集管理這些圖表\nLogs Page 數據功能，顯示匯入的數據\nQuery DSL Elastic 提供了一套查詢語法 DSL (Domain Specific Language)，可透過 RESTful 或 Kibana 的介面來使用，這邊介紹幾個範例\n  Match\n例如查詢 IIS 中，有那些 Request 回應 500\n GET /_search { \u0026quot;query\u0026quot;: { \u0026quot;match\u0026quot;: { \u0026quot;iis.access.response_code\u0026quot;: { \u0026quot;query\u0026quot;: 500, \u0026quot;type\u0026quot;: \u0026quot;phrase\u0026quot; } } } }    Wildcard\n例如查詢 IIS 中，有那些 Request url like */app/\n GET /_search { \u0026quot;query\u0026quot;: { \u0026quot;wildcard\u0026quot;: { \u0026quot;iis.access.url\u0026quot;: \u0026quot;*/app\u0026quot; } } }    Prefix\n例如查詢 IIS 中，url 以 /en/app 開頭的 Request 有那些\n GET /_search { \u0026quot;query\u0026quot;: { \u0026quot;prefix\u0026quot;: { \u0026quot;iis.access.url\u0026quot;: \u0026quot;/en/app\u0026quot; } } }    參考 Elastic 官網\n","description":"介紹 Kibana 個人應用實例","id":19,"section":"posts","tags":["Kibana"],"title":"如何使用 Kibana 分享日誌","uri":"https://reddtsai.github.io/zh/posts/elk_kibana/"},{"content":"版本\n Filebeat 6\n環境 Windows 10  1. 下載 Filebeat Download Filebeat for Windows\n2. 安裝 Filebeat 解壓縮至 C:\\Program Files\\Filebeat，以 admin 角色開啟 PowerShell\n1 2  cd \u0026#39;C:\\Program Files\\Filebeat\u0026#39; .\\install-service-filebeat.ps1   3. 設定 Filebeat 編輯 filebeat.yml，設定 elasticsearch 和 kibana 的位置\n1 2 3 4  output.elasticsearch: hosts: [\u0026#34;localhost:9200\u0026#34;] setup.kibana: host: \u0026#34;localhost:5601\u0026#34;   4. 設定 Filebeat 模組 收集 IIS Log\n編輯 filebeat\\module\\iis\\access\\manifest.yml\n1 2 3  default.paths: default: - C:/inetpub/logs/LogFiles/*/*.log   啟用 iis 模組\n1  .\\filebeat.exe modules enable iis   5. 啟動 Filebeat 服務 1 2  .\\filebeat.exe setup Start-Service filebeat   ","description":"介紹在 Windows 中安裝 Filebeat","id":20,"section":"posts","tags":["Filebeat","Windows"],"title":"Windows 如何安裝 Filebeat","uri":"https://reddtsai.github.io/zh/posts/elk_windowsfilebeat/"},{"content":"版本\n ElastAlert 0.2\n環境 CentOS 7\n安裝需求 python 2.7 python-dev python-pip dependency Package，參考 ElastAlert requirements.txt  1. 安裝 PIP、DEV 確認是否已安裝 python 2.7\n1  python --version   安裝 python-pip\n1 2 3 4 5  sudo yum -y install python-devel sudo yum -y install epel-release sudo yum -y install python-pip pip --version sudo pip install --upgrade pip   2. 安裝 ElastAlert 確認套件，安裝的過程中可能會遇到相依套件的問題，請參考 ElastAlert requirements.txt 中的需求套件清單\n1  pip list   例如，在安裝 blist 套件時，需要安裝 GCC\n1  sudo yum -y install gcc   例如，在更新 requests 套件時，需要強制移除安裝\n1  sudo pip install requests --ignore-installed requests   安裝 ElastAlert\n1  sudo pip install elastalert   3. 設定 ElastAlert 在 ElastAlert 目錄下新增設定檔 config.yaml。以我的環境為例 /usr/lib/python2.7/site-packages/elastalert\n建議複製 ElastAlert config.yaml.example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  # This is the folder that contains the rule yaml files# Any .yaml file will be loaded as a rulerules_folder:/usr/lib/python2.7/site-packages/elastalert/alert_rules# How often ElastAlert will query Elasticsearch# The unit can be anything from weeks to secondsrun_every:# seconds:minutes:1# hours:# ElastAlert will buffer results from the most recent# period of time, in case some log sources are not in real timebuffer_time:minutes:15# The Elasticsearch hostname for metadata writeback# Note that every rule can have its own Elasticsearch hostes_host:elasticsearch.example.com# The Elasticsearch portes_port:9200# elastalert-create-index to set a mappingwriteback_index:elastalert_statusalert_time_limit:days:2  4. 設定 Elasticsearch Client 確認 Elasticsearch Client 的版本和 Elasticsearch 的版本相符。以我的環境為例，需要將 lasticsearch Client 更新至 6.X 版\n1 2 3  pip list sudo pip uninstall elasticsearch sudo pip install \u0026#34;elasticsearch\u0026lt;7\u0026#34;   在 Elasticsearch 增加一個 ElastAlert 的索引\n1  elastalert-create-index   5. 設定通知規則 新增通知規則設定檔 filebeat_frequency.yaml。以我的環境為例 /usr/lib/python2.7/site-packages/elastalert/alert_rules\n這裡以 IIS Log 為例，當 http status != 200 時，發送一個訊息至 Slack\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  es_host:elasticsearch.example.comes_port:9200name:Examplefrequencyruletype:frequencyindex:filebeat-*# (Required, frequency specific)# Alert when this many documents matching the query occur within a timeframenum_events:50# (Required, frequency specific)# num_events must occur within this amount of time to trigger an alerttimeframe:hours:4filter:- query:query_string:query:\u0026#34;NOT iis.access.response_code: 200 AND event.dataset: iis.access\u0026#34;alert:- slack:slack_webhook_url:\u0026#34;http://slack_webhook_url\u0026#34;  測試規則設定檔\n1  elastalert-test-rule alert_rules/filebeat_frequency.yaml   6. 設定 ElastAlert 服務 執行測試\n1  python -m elastalert --verbose --rule alert_rules/filebeat_frequency.yaml   新增服務\n1 2 3 4  sudo mkdir -p /etc/elastalert/rules cd /etc/elastalert/ sudo cp /usr/lib/python2.7/site-packages/elastalert/config.yaml config.yaml sudo cp /usr/lib/python2.7/site-packages/elastalert/alert_rules/filebeat_frequency.yaml rules/filebeat_frequency.yaml   修改 config.yaml\nrules_folder: /etc/elastalert/rules\n新增服務設定檔\n1 2  cd /etc/systemd/system/ sudo vi elastalert.service   elastalert.service\n1 2 3 4 5 6 7 8 9 10 11 12  [Unit] Description=elastalert [Service] Type=simple User=root Group=root Restart=on-failure WorkingDirectory=/usr/lib/python2.7/site-packages/elastalert ExecStart=/usr/bin/elastalert --config /etc/elastalert/config.yaml --rule /etc/elastalert/rules/filebeat_frequency.yaml [Install] WantedBy=multi-user.target   啟動服務\n1 2 3  sudo systemctl enable elastalert.service sudo systemctl start elastalert.service sudo systemctl status elastalert.service   參考 ElastAlert Repo\nElastAlert Doc\n","description":"介紹在 CentOS 中安裝 ElastAlert","id":21,"section":"posts","tags":["ElastAlert","CentOS"],"title":"CentOS 7 如何安裝 ElastAlert","uri":"https://reddtsai.github.io/zh/posts/elk_centoselastalert/"},{"content":"從事軟體工程師的工作十年了，被稱過軟體工程師(PG)、研發工程師(RD)、後端工程師(Backend)、系統設計師(SD)、系統架構師(SA) \u0026hellip;，雖然職稱一直再變，但自己感覺工作內容並無太大的改變，最近剛好看到一篇有趣的文章，是關於軟體開發者的 Roadmap，並跟自己作個比較。\nNowadays Web Developer 今年5G上市了，在這個網路世代，我突然成了 web developer，到底什麼是 web developer？用Kamran Ahmed的圖可看出現今 web developer 大致可分為 backend、frontend及 devops。另外也列出了 web developer 需具備的技能。\nBackend Skill Tree 後端在搞什麼？看完下方 Backend Roadmap 還想當後端工程師嗎？自己也是後端工程，那就透過這張圖來盤點一下自己(看看自己有多爽🤥)。\n以個人經驗將這張 Roadmap 分為以下幾個大項\n Data Transfer\nDNS、FTP、HTTP、TCP、RPC \u0026hellip; Data Storage\nCache、Database、File \u0026hellip; Host\nDomain、OS、Docker、IIS、Nginx、AWS、GCP、Azures \u0026hellip; Programming\nPython、Golang、.NET、Node.js、Git\u0026hellip; Test\nUnit、Intergration、Load Deployment\nCI、CD Other\nLog、Monitor、Elastic  經以上這些項目來盤點自己是不是個後端工師的同時，也用它記錄分享一些實例和個人經驗(希望未來能補完🙏🙏🙏)。\n以下是Kamran Ahmed所畫後端工程師的技能樹。\nFrontend Skill Tree 前端在搞什麼？以下是Kamran Ahmed所畫前端工程師的技能樹。\nDevOps Skill Tree 運維在搞什麼？以下是Kamran Ahmed所畫運維工程師的技能樹。\nReference 參考來源\ndeveloper-roadmap by Kamran Ahmed.\n","description":"簡介後端工作和技能","id":22,"section":"posts","tags":["Backend"],"title":"前端？後端？後端工程師搞什麼？","uri":"https://reddtsai.github.io/zh/posts/backend_skill/"},{"content":"歷史 Elastic 是由 Elasticsearch、Logstach 和 Kibana 這三個開源項目所組成，最初是由 Shay 編寫的 Elasticsearch 這個食譜搜尋引擎開始，後來與 Jordan 開發的 Logstach 和 Rashid 開發的 Kibana 共同合作。隨後推出一些商業服務並成立 Elastic 這個品牌。\nElasticsearch Elasticsearch 是個搜尋分析尋引擎，能夠集中儲存數據和分散運作，使用 RESTful 方式提供服務。\nLogstach Logstach 是個數據處理工具，將不同來源的資料轉化、解析或加密，然後將數據發送至指定的儲存體。\nKibana Kibana 為 Elastic 的介面(UI)，可用來管理配置 Elastic，或透過 DSL、SQL 查詢語法，將 Elasticsearch 數據分享。\n參考來源 Elastic 官網\n下篇文章會介紹如何利用 Elastic 處理日誌\n","description":"介紹 Elastic 個人應用實例","id":23,"section":"posts","tags":["Elastic"],"title":"Elastic 簡介","uri":"https://reddtsai.github.io/zh/posts/elk/"},{"content":"當你面對數個虛擬機、資料庫、成百的服務、應用程式生成的日誌，你需要一個能處理這巨量負雜日誌的產品，這裡介紹 Elastic 這個產品來協助你，必免自己造輪子。將由下圖的內容來說明，如何使用 Elastic 處理日誌你的日誌。\n日誌收集 首先是如何收集匯整你的日誌？例如你有 IIS、NGINX、MySQL、APP 多種不同類型的日誌，你需要將它們收集起來存放，這裡會使用 FileBeat 和 Logstash 來收集。\n FileBeat 是匯整轉發日誌工具，可使用它內建模組或自訂格式來收集日誌，並將收集來的數據解析發送到 Logstash 或 Elasticsearch 儲存。\n 範例如何使用 Filebeat 收集日誌\n  Logstash 是接收轉發日誌中介服務，從過濾器接收不同形式的來源，透過建構結構來分析轉換成通用格式，再輸出到 Elasticsearch 或其它儲存設備。\n日誌存儲 接下來透過 Elasticsearch 來儲存收集來的資料。\n Elasticsearch 是一個分散式、RESTful 風格的搜尋和數據分析引擎，它是 Elastic 的核心，很像資料庫提供搜索和儲存。\n 範例CentOS 7 如何安裝 Elasticsearch\n 日誌分析 Elastc 提供一個強大的 UI 介面 Kibana，它能協助你分析 視覺化、分享收集來的數據。\n Kibana 是個強大的 UI，透過網頁呈現，提供多種儀表皮和圖表來分享數據。\n 範例如何使用 Kibana 分享日誌\n 日誌監控 最後，Elastc 也提供數據、效能監控服務，這部分屬於白金服務需要付費，也有一些替代方，例如 ElastAlert、Sentinl。\n 範例CentOS 7 如何安裝 ElastAlert\n","description":"介紹 Elastic 個人應用實例","id":24,"section":"posts","tags":["Elastic"],"title":"如何利用 Elastic 處理日誌","uri":"https://reddtsai.github.io/zh/posts/elk_logging/"},{"content":"Filebeat 是個檔案分析工具，最常用來收集日誌檔，收集的過程分為\n 收集數據 (讀取日誌) 解析數據\n常見的日誌格式(IIS、NGINX、MySQL)大多可透過 Filebeat 內建模組來解析，也可透過新增模組來客製格式，以下會說明該如何新增或設定 Filebeat 模組。 傳送數據 (Logstash 或 Elasticsearch 儲存)   版本\n Filebeat 6\n安裝請參考下一篇文章Windows 如何安裝 Filebeat   設定模組 Filebeat 提供多樣模組來收集常見的日誌，這邊以 IIS 日誌為例，說明如何設定模組。\n  設定日誌路徑\n編輯 [Windows 安裝路徑]\\filebeat\\module\\iis\\access\\manifest.yml\n #加入 IIS 日誌路徑 default.paths: default: - C:/inetpub/logs/LogFiles/*/*.log    啟用模組\n開啟 IIS 模組，在 PowerShell 執行下方命令\n cd [Windows 安裝路徑] .\\filebeat.exe modules enable iis    新增模組 新增一個模組後，可看到所產生的檔案結構，以下方我所建立的 nlog module 為例\nfilebeat\n├ module\n│ ⎩ nlog\n│ ⎩ app\n│ ├ manifest.yaml\n│ ├ config\n│ │ ⎩ fileset.yml\n│ ⎩ ingest\n│ ⎩ pipeline.json\n├ modules.d\n│ ⎩ nlog.yml.disabled\n 新增一個模組需透過 Beats 程式碼來逹成，這裡只會說明新模組需要作那些設定，完整資訊請參考 github Beats repository\n   manifest.yaml\nmanifest 控制檔，設定模組參考位置\n #日誌路徑 var: － name: paths os.windows － C:/log/*.log #template 參考路徑 input: config/fileset.yml #Ingest Pipeline 參考路徑 ingest_pipeline: ingest/pipeline.json    fileset.yml\nfileset 輸入組態檔，設定輸入位置、排除輸入檔案、排除輸入行及多行組合\n #排除 .gz 檔 exclude_files: [\u0026quot;.gz$\u0026quot;]    pipeline.json\nlasticsearch ingest node pipeline configurations\n  modules.yml.disabled\n模組開關\n  測試模組 新增或設定好模組，先由測試確認完後再上線\n  測試設定檔\n.\\filebeat.exe test config -c filebeat.yml\n.\\filebeat.exe test output filebeat.yml\n  執行 Filebeat\n.\\filebeat.exe -e -c filebeat.yml -d \u0026ldquo;*\u0026rdquo;\n 注意\n請先清除前次測試所讀取的記錄，刪除目錄 filebeat\\data\\registry\n   檢查 Ingest \u0026amp; Pipeline\n透過 elasticsearch api 查詢 Ingest \u0026amp; pipeline (例如 IIS 模組 pipeline filebeat-6.7.0-iis-access-default)\ncurl -X GET http://elasticsearch:9200/_cat/indices?v\ncurl -X GET http://elasticsearch:9200/_ingest/pipeline\ncurl -X GET http://elasticsearch:9200/_ingest/pipeline/filebeat-6.7.0-iis-access-default\n 如果測試 pipeline 有問題，需要刪除舊的 pipeline.json\n  curl -X DELETE http://elasticsearch:9200/_ingest/pipeline/filebeat-6.7.0-iis-access-default    確認資料\n開啟 Kibana，透過 Logs 介面，確認是否有顯示 log 資料\n  參考 Elastic 官網\n","description":"透過 Filebeat 收集系統、應用程式 Log","id":25,"section":"posts","tags":["Filebeat"],"title":"如何使用 Filebeat 收集日誌","uri":"https://reddtsai.github.io/zh/posts/elk_iisfilebeat/"},{"content":"版本\n Kibana 6.8\n環境 CentOS 7  1. 安裝 OpenJDK 1 2  sudo yum install java-1.8.0-openjdk-devel java -version   2. 安裝 Elasticsearch 簽章公鑰 1  rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch   3. 安裝 Kibana 建立 Kibana 套件容器設定檔 /etc/yum.repos.d/kibana.repo\n填入套件容器參數\n1 2 3 4 5 6 7 8  [kibana-6.x] name=Kibana repository for 6.x packages baseurl=https://artifacts.elastic.co/packages/6.x/yum gpgcheck=1 gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch enabled=1 autorefresh=1 type=rpm-md   安裝 kibana\n1  sudo yum install kibana   4. 配置 kibana kibana 配置檔 /etc/kibana/kibana.yml\n1 2  elasticsearch.hosts: http://localhost:9200 server.host: 0.0.0.0   5. 設定防火牆和IP 新增\n1 2 3 4 5  sudo firewall-cmd --new-zone=kibana --permanent sudo firewall-cmd --reload sudo firewall-cmd --zone=kibana --add-source=\u0026lt;IP_ADDRESS\u0026gt;/32 --permanent sudo firewall-cmd --zone=kibana --add-port=5601/tcp --permanent sudo firewall-cmd --reload   修改\n1 2  sudo firewall-cmd --zone=kibana --add-source=\u0026lt;IP_ADDRESS\u0026gt; --permanent sudo firewall-cmd --reload   測試\n1 2  sudo firewall-cmd --zone=kibana --list-all sudo netstat -plnt   6. 啟動 kibana 服務 1 2  sudo systemctl enable kibana.service sudo systemctl start kibana.service   測試 kibana\nhttp://localhost:5601\n1  sudo systemctl status kibana.service   也可檢查服務記錄訊息\n1  sudo journalctl --unit kibana --since \u0026#34;20 min ago\u0026#34;   參考 Elastic 官網\n","description":"介紹在 CentOS 中安裝 Kibana","id":26,"section":"posts","tags":["Kibana","CentOS"],"title":"CentOS 7 如何安裝 Kibana","uri":"https://reddtsai.github.io/zh/posts/elk_centoskibana/"},{"content":"版本\n Elasticsearch 6.8\n環境 CentOS 7  1. 安裝 OpenJDK 1 2  sudo yum install java-1.8.0-openjdk-devel java -version   2. 安裝 Elasticsearch 簽章公鑰 1  rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch   3. 安裝 Elasticsearch 建立 Elasticsearch 套件容器設定檔 /etc/yum.repos.d/elasticsearch.repo\n填入套件容器參數\n1 2 3 4 5 6 7 8  [elasticsearch-6.x] name=Elasticsearch repository for 6.x packages baseurl=https://artifacts.elastic.co/packages/6.x/yum gpgcheck=1 gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch enabled=1 autorefresh=1 type=rpm-md   安裝 Elasticsearch\n1  sudo yum install elasticsearch   4. 啟動 Elasticsearch 服務 1 2  sudo systemctl enable elasticsearch.service sudo systemctl start elasticsearch.service   測試 Elasticsearch\n1 2  sudo systemctl status elasticsearch.service curl -X GET http://localhost:9200   也可檢查服務記錄訊息\n1  sudo journalctl --unit elasticsearch --since \u0026#34;20 min ago\u0026#34;   5. 設定防火牆和IP 新增\n1 2 3 4 5  sudo firewall-cmd --new-zone=elasticsearch --permanent sudo firewall-cmd --reload sudo firewall-cmd --zone=elasticsearch --add-source=\u0026lt;IP_ADDRESS\u0026gt;/32 --permanent sudo firewall-cmd --zone=elasticsearch --add-port=9200/tcp --permanent sudo firewall-cmd --reload   修改\n1 2  sudo firewall-cmd --zone=elasticsearch --add-source=\u0026lt;IP_ADDRESS\u0026gt; --permanent sudo firewall-cmd --reload   測試\n1 2  sudo firewall-cmd --zone=kibana --list-all sudo netstat -plnt   6. 配置 Elasticsearch Elasticsearch 配置檔 /etc/elasticsearch/elasticsearch.yml\nElasticsearch JVM 配置檔 /etc/elasticsearch/jvm.options\n✳︎記憶體配置不可小放實體記憶體50%\n1 2 3  -Xms2g -Xmx2g network.host: 0.0.0.0   參考 Elastic 官網\n參考官方說明\n","description":"介紹在 CentOS 中安裝 Elasticsearch","id":27,"section":"posts","tags":["Elasticsearch","CentOS"],"title":"CentOS 7 如何安裝 Elasticsearch","uri":"https://reddtsai.github.io/zh/posts/elk_centoselastic/"}]