[{"content":"隨著雲端時代的到來，讓軟體開發與雲端平台變得密不可分。雲端有那些好處？該選那個雲端供應商 AWS、Azure、GCP、阿里云？？網上有很多論述可供參考。當你要加入雲端時，千萬不要直接將公司的 Server 搬上雲端，因為很有可能讓公司發不出薪水。\nHow 那要如何加入雲端？我會建議你以下 Step：\n 認識雲端 架構規劃 選擇供應商 試算成本 申請預算 打統編報稅  架構規劃的部分，只有適合你的架構，沒有正確答案，建議先瞭解以下幾個雲端主流架構：\n Serverless\nGCP:App Engine\nAzure:Functions\nAWS:Lambda VM\nGCP:Compute Engine\nAzure:VM\nAWS:EC2 Container\nGCP:Kubernetes Engine\nAzure:Kubernetes Service\nAWS:Elastic Kubernetes Service  ","description":"如何加入雲端？","id":0,"section":"posts","tags":["GCP"],"title":"快樂上雲端","uri":"https://reddtsai.github.io/zh/posts/gcp/"},{"content":"分享個人如何將雲端虛擬機器結合到開發工作中，例如，當專案需要二台主機，一台用來作使用者測試，另一台給未來營運使用，以下介紹個人的作法給大家參考。未來作持續更新部署(CI/CD)或自動擴展(Auto Scaling)也會使用這個自動化腳本。\nCreate a Compute Engine instance 透過 CLI 的方式來介紹如何建立一台虛擬機器，這次使用的是 Google Cloud 提供的虛擬機器 Compute Engine。\n請先準備好你的 Google 帳號和 SDK  設定 VM 所在區域 (Zone) 1 2  gcloud config set compute/zone [zone] gcloud config set compute/region [region]    東南亞可選擇新加坡，東北亞可選擇首爾。 [Regions and Zones](https://cloud.google.com/compute/docs/regions-zones)   新增一台 VM (Compute Engine) 1  gcloud compute instances create [instance]    機器類型：虛擬化硬體規格。ex. --machine-type=g1-small 作業系統：Windows, Linux。ex. --image-family=debian-9   設定防火墻 (Firewall)\nEnable port 80 for web site 1  gcloud compute firewall-rules create allow-80 --allow tcp:80    建立負載平衡 (Load balancing)\n如果你需要建立負載平衡，依照 GCP 說明，要使用叢集(cluster)來建立 VM(取代第二步)。 1 2 3 4 5 6 7  gcloud compute instance-templates create [template] gcloud compute target-pools create [pool] gcloud compute instance-groups managed create [group] \\  --base-instance-name [name] \\  --size 2 \\  --template [template] \\  --target-pool [pool]   負載平衡：\n1 2 3  gcloud compute forwarding-rules create [loadbalance] \\  --ports 80 \\  --target-pool [pool]     完成後，你可以試著透過 SSH 登入 VM：\n1  gcloud compute ssh [instance]   Create Deployment Script 接下來，將建立容器的動作，透過 shell script 製作成腳本。後續你可將這個腳本加入版本控制，持續更新部署。\n使用者測試環境，Create_SIT_GCE.sh。\n1 2 3 4 5 6 7 8 9  MY_INSTANCE_NAME=\u0026#34;sit-vm\u0026#34; ZONE=asia-east1-a gcloud compute instances create $MY_INSTANCE_NAME \\  --image-family=debian-9 \\  --image-project=debian-cloud \\  --machine-type=g1-small \\  --scopes userinfo-email,cloud-platform \\  --zone $ZONE \\   營運環境，Create_PRD_GCE.sh。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  gcloud config set compute/zone asia-east1-a gcloud config set compute/region asia-east1 gcloud compute instance-templates create prd-template \\  --image-family=debian-9 \\  --image-project=debian-cloud \\  --machine-type=g1-small \\  --scopes userinfo-email,cloud-platform gcloud compute target-pools create prd-pool gcloud compute instance-groups managed create prd-group \\  --base-instance-name prd \\  --size 2 \\  --template prd-template \\  --target-pool prd-pool gcloud compute forwarding-rules create lb-prd \\  --ports 80 \\  --target-pool prd-pool   Clean up Compute Engine instance 不需要時清除 VM，避免計費問題。\n1 2 3 4 5 6  gcloud compute forwarding-rules delete [loadbalance] gcloud compute instance-groups managed delete [group] gcloud compute target-pools delete [pool] gcloud compute instance-templates delete [template] gcloud compute instances delete [instance] gcloud compute firewall-rules delete allow-80   Reference Compute Engine\n","description":"Write a script to create Compute Engine","id":1,"section":"posts","tags":["GCE"],"title":"快速建立 Compute Engine","uri":"https://reddtsai.github.io/zh/posts/gcp_computeengine/"},{"content":"至從開始使用 dotnet core 後，個人的開發方式也從 Visual Studio on Windows，轉換為 Visual Studio Code on Mac，轉變的過程有很多值得記錄。例如最近開發上需要安裝一個 dotnet 工具，如果是用 Visual Studio，會交由擴充管理員來安裝工具，那在沒有 Visual Studio 的協助下呢？這裡會介紹如何使用 CLI 來安裝 dotnet-ef。\nRequirements 首先準備好環境，以我為例：\n macOS 10.15 .NET Core 3.1  環境確認後，透過以下指令，列出已安裝的 dotnet tool。\n1 2  dotnet tool list dotnet tool list -g   g：全域 Install 透過 dotnet CLI 來安裝工具，這裡介紹安裝 dotnet-ef 工具到全域或本地。\n Global 1  dotnet tool install dotnet-ef -g    Local\n安裝本地工具，需要定義 manifest file。首先準備好 dotnet project，在專案下執行以下命令，它會產生一個 dotnet-tools.json 記錄本地工具。 1 2  dotnet new tool-manifest dotnet tool install   .config/dotnet-tools.json\n1 2 3 4 5 6 7 8 9 10 11 12  { \u0026#34;version\u0026#34;: 1, \u0026#34;isRoot\u0026#34;: true, \u0026#34;tools\u0026#34;: { \u0026#34;dotnet-ef\u0026#34;: { \u0026#34;version\u0026#34;: \u0026#34;3.1.3\u0026#34;, \u0026#34;commands\u0026#34;: [ \u0026#34;dotnet-ef\u0026#34; ] } } }     Update 更新 dotnet tool，一樣分為全域和本地，如下示範：\n Global 1  dotnet tool update -g dotnet-ef    Local 1  dotnet tool update dotnet-ef     Uninstall 卸載已安裝的工具：\n Global 1  dotnet tool uninstall -g dotnet-ef    Local 1  dotnet tool uninstall dotnet-ef     Reference .NET Core tools\n","description":"使用 CLI 來安裝 dotnet-ef","id":2,"section":"posts","tags":["dotnet"],"title":"在 Mac 上安裝 dotnet tool","uri":"https://reddtsai.github.io/zh/posts/dotnet_tool/"},{"content":"開發 .NET 應用程式在處理資料時，都會建立模型類別(Model)，特別像是 MVC 的專案，而當資料要儲存到資料庫時，資料庫需要產生對映 Schema 來儲存。這時千萬別馬上開始，先瞭解幾個專有名詞 code first、model first、database first，然後，再利用自動生成工具來減少你的工作，工具像是 PMC Tool - Migrations、POCO Entity \u0026hellip;。\n不過這些工具，個人覺得在 mac 上，使用起來不是很順手，個人較習慣使用 CLI Tool 的方式，接下來用個實例說明反向工程，如何用 MySQL Schema 生成模型類別到專案中。\n我所使用的環境：\n Mac Visual Studio Code dotnet core 3.0 dotnet-ef Makefile  Installing 請先建立好你的 dotnet project，然後確認已安裝：\n CLI Tool\n安裝 dotnet-ef 工具，用來作模型移轉。 1  dotnet tool install --global dotnet-ef    Database Provider\n我所使用的是 MySQL，需安裝 MySql 資料庫提供者。 1  dotnet add package Pomelo.EntityFrameworkCore.MySql    PROVIDER\n  EntityFrameworkCore.Design\n如果你是使用 .NET Core 2.1 以上的版本，.NET Core SDK 已包含 Design，可跳過這一步。 1  dotnet add package Microsoft.EntityFrameworkCore.Design     Scaffold 當資料庫和工具準備完成，透過 dbcontext scaffold 指令來進行反向工程，它會讀取資料庫的資訊，像 tables, columns, constraints, and indexes \u0026hellip;，然後生成 DbContext.cs 和 Models.cs。\n1  dotnet ef dbcontext scaffold \u0026#34;server=127.0.0.1;port=3306;user=root;password=pwd;database=db\u0026#34; Pomelo.EntityFrameworkCore.MySql   Script 最後，建立 makefile 腳本持續更新模型\n1 2 3 4 5 6  efScaffold: dotnet ef dbcontext scaffold \u0026#34;server=127.0.0.1;port=3306;user=root;password=pwd;database=db\u0026#34; \\  Pomelo.EntityFrameworkCore.MySql \\  -o Repositories/Entities \\  --context-dir Repositories -c LotteryContext \\  -p src -f   Reference Side Project\nReverse Engineering\n","description":"利用 dotnet-ef 實作 DB 反向工程","id":3,"section":"posts","tags":["EF"],"title":"用 dotnet ef 工具，從 MySQL 自動生成 Model.cs","uri":"https://reddtsai.github.io/zh/posts/dotnet_efreverse/"},{"content":"後端工程師的工作中很常需要一個常駐程式，幫我們處理非即時的工作或例行性的排程工作，在 Windows Sever 中有大家熟悉的服務和工作排程，那 Unix-Like Server 呢？？你可能常常聽到 Daemon (守護)，很難跟 Service 聯想在一起，在 Unix-Like 系統中常會將背景程式稱作 Daemon。接下來透過工作上的實例來說說這個 Daemon。這個工作需求是要在 Debian 下安裝 cloud sql proxy，然後，要它在背景執行，開機時自己啟動，在這裡作個記錄 。\nSystemd - 服務管理機制 這次工作所使用的系統為 Debian，在 Debian 及其它 Unix-Like 系統中，都有個服務管理機制 systemd，透過這個機制來啟動、關閉與觀察系統服務或你所自定的服務。\n可分為幾個類型如下：\n .service 一般服務 .socket 程序資料交換 .target 執行環境 .mount 檔案系統掛載 .automount 檔案系統掛載 .path 偵測特定檔案或目錄 .timer 循環執行   存放位置\n/usr/lib/systemd/system/：啟動腳本設定檔\n/run/systemd/system/：執行過程中所產生的服務腳本\n/etc/systemd/system/：管理員所建立的執行腳本\n 那要怎麼將 cloud sql proxy 加入 systemd 中？？\n本次會使用一般服務 cloud_sql_proxy.service，將檔案放入啟動位置 /etc/systemd/system/。\n範例 /etc/systemd/system/cloud_sql_proxy.service\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  # 服務解釋、相依性 [Unit] Description=Connecting MySQL Client from Compute Engine using the Cloud SQL Proxy Requires=networking.service After=networking.service # 服務執行的指令參數 [Service] WorkingDirectory=/usr/local/bin ExecStart=/usr/local/bin/cloud_sql_proxy -dir=/var/run/cloud-sql-proxy -instances=redd-side-project:asia-east1:db-mysql-001=tcp:3306 Restart=always StandardOutput=journal User=root # 要掛載哪個 target 底下 [Install] WantedBy=multi-user.target   Systemctl - 服務管理指令 初步認識 systemd 後，還需認識一個管理程式 systemctl，主要會透過 systemctl 的指令來處理我們的服務。\n接下來透過 systemctl 來操控 cloud_sql_proxy.service。\n啟用/停用，下次開機生效\n1 2  sudo systemctl enable cloud-sql-proxy.service sudo systemctl disable cloud-sql-proxy.service   立刻啟動/關閉\n1 2  sudo systemctl start cloud-sql-proxy.service sudo systemctl stop cloud-sql-proxy.service   列出狀態\n1  sudo systemctl status cloud-sql-proxy.service   常用指令\n1 2 3 4 5 6 7 8 9 10  -- 重新載入設定檔 sudo systemctl daemon-reload -- 列出所有啟動的 unit sudo systemctl -- 列出所有 .service sudo systemctl list-units --type=service --all -- 列出所有 cpu 為名 .service sudo systemctl list-units --type=service --all | grep cpu -- 列出相依 sudo systemctl list-dependencies   到這邊就完成了這次的工作任務，將 cloud_sql_proxy.service 在背景執行及開機時自己啟動。\nTimer - 排程 一開始除了服務，還有提到例行性的排程工作，那要怎麼使服務定期執行某個工作？？現學現賣，拿 systemd.timer 來作個實例(大多數的資訊都會用 crond 來定期處理服務😸😸)。\n我希望每日執行一次我的 APP\n 啟動系統 timer.target app.service 你的工作 app.timer 你的排程(與你的工作同名)\n範例 side project\n/etc/systemd/system/app.service  1 2 3 4 5 6 7  [Unit] Description=taiwan lottery scarper [Service] WorkingDirectory=/opt/app/gce/env/bin ExecStart=/opt/app/gce/env/bi/python /opt/app/app.py [Install] WantedBy=multi-user.target   /etc/systemd/system/app.timer\n1 2 3 4 5 6 7 8 9  [Unit] Description=scheduling taiwan lottery scarper [Timer] OnActiveSec=1m OnCalendar=Sun *-*-* 01:00:00 Persistent=true Unit=lotto-scraper.service [Install] WantedBy=multi-user.target   Reference 鳥哥\n","description":"將 cloud sql proxy 加入系統服務","id":4,"section":"posts","tags":["Daemon","Debian"],"title":"系統服務 In Debian","uri":"https://reddtsai.github.io/zh/posts/os_debiandaemon/"},{"content":"不論公司 project 或個人 side project，都會遇到資料儲存的需求，這時可能就是\n 求 DBA 自己安裝 向 Infra 申請 開始學 SQL Google  Why Cloud SQl 我為什麼選擇 Cloud SQl？原因只有一個，就是快\n 安裝快 上手快 擴展快 運維快  這裡會用 GCP 提供的 Cloud SQl 來說明，當然也可以選擇 AWS、Azure、阿里雲的產品。\nInstall MySQL 安裝快，只需幾分鐘就能建立一台 DB。開始安裝前你需要先有：\n 啟用 Google Cloud (你需要一組 Google 帳戶和一張信用卡) 安裝 cloud SDK  1  brew cask install google-cloud-sdk   安裝 DB 只需開啟終端機，執行下段命令。\n1  gcloud sql instances create [INSTANCE_NAME] --tier=[MACHINE_TYPE] --region=[REGION]      INSTANCE_NAME：命名你的 Database instance。\n  MACHINE_TYPE：Database 規格。Price\n  REGION：Instance 存放位置。Region\nCreating instances 說明\n   另外，你不習慣冷冰冰的命令，GCP 也提供 UI 介面讓你設定。\nConnection 上手快，你可快速連至 cloud database，官方提供多種方式及各程式語言的完整範例說明，減少你摸索的時間。\n這裡介紹透過 cloud sql proxy 快速連到剛建立的 DB。首先，安裝 cloud sql proxy\n1 2  gcloud components install cloud_sql_proxy ./cloud_sql_proxy -instances=\u0026lt;INSTANCE_CONNECTION_NAME\u0026gt;=tcp:3306   如下圖所示，你可以找到 INSTANCE_CONNECTION_NAME\n再來使用 MySQL workbench 來作個本機連線測試，如果你還沒安裝，請先透過以下命令來安裝。\n1  brew cask install mysqlworkbench   Replication 擴展快、運維快，當你初步認識 SQL 後，再進階就是效能跟穏定，最長聽到的就是 HA(high availability)，而在 cloud sql 你也只需要作簡單的設定來逹成 HA，讓你的 DB 擁有備援。\n另一個例子，在 cloud sql 新增一個讀取位置，分散流量來提升效能。\nReference 本次實作的費用\ncloud sql for mysql\n","description":"Cloud SQl for MySQL on Google Cloud Platform","id":5,"section":"posts","tags":["MySQL"],"title":"在雲上使用 MySQL","uri":"https://reddtsai.github.io/zh/posts/gcp_mysql/"},{"content":"身為一位軟體工程師怎麼可以沒有 Blog，再加上工程師最愛挖洞給自己跳，所以一定要自己架Blog😭😭😭。這裡跟大家介紹個靜態網站生成引擎 HUGO，接著透過 HUGO 來建立一個美美又免費的Blog。\nAbout Hugo HUGO 是由 go 所編寫的靜態網站生成器，最初由 Steve Francia 創立，以開源專案方式持續更新。Hugo 提供將資料檔案、i18n 包、組態、布局模板、靜態檔案，以及用 Markdown 編寫的內容，生成一個完整的靜態網站。\nCreate a Hugo site 以下說明你可能需要一點程式基楚，這裡會使用 mac os 來作說明。(個人是使用蘋果筆電😅😅)\n1.安裝 Hugo 使用 homebrew 安裝 Hugo，在終端機中輸入\n1  brew install hugo   驗証安裝成功，確認 hugo 版本。\n1  hugo version   2.產生新網站 透過 new 命令來產生一個新站台，在終端機中操作\ncd YourWorkSpace hugo new site myBlog 3.美化網站 加入外觀主題到剛建立好的網站，在這挑選一個外觀主題。\n我用 Ananke 來作說明，在終端機中操作\n1 2 3  cd myBlog git init git submodule add https://github.com/budparr/gohugo-theme-ananke.git themes/ananke   設定主題\n1  echo \u0026#39;theme = \u0026#34;ananke\u0026#34;\u0026#39; \u0026gt;\u0026gt; config.toml   4.加入文章 使用 new 命令來產生一篇文章，在終端機中操作\n1  hugo new posts/my-first-post.md   你可以用 markdown 編輯內容。\n5.啟動網站 啟動你的 Blog\n1  hugo server -D   打開瀏覽器 http://localhost:1313/\n參考來源 謝謝 HUGO\n","description":"透過HUGO建立Blog","id":6,"section":"posts","tags":["Hugo"],"title":"建立免費的個人博客 By HUGO","uri":"https://reddtsai.github.io/zh/posts/hugo_hello/"},{"content":"Hello，大家好我是Redd，是位網路後端軟體工程師(Internet Backend Engineer)，在此一邊記錄並與大家分享自己的工作經驗。\n","description":"about page of Redd's side project","id":7,"section":"","tags":null,"title":"About","uri":"https://reddtsai.github.io/zh/about/"},{"content":"Elastic 提供一個強大的 UI 介面 Kibana，透過它能更有效的分享與呈現 Elasticsearch 中的數據，接下來會以本身使用的案例，來介紹如何使用 Kibana。\n 版本\n Kibana 6\n安裝請參考下一篇文章CentOS 7 如何安裝 Kibana   Discover Page 數據探索功能，使用 Elasticsearch Index、Time Range 和 Query DSL 過濾搜索，顯示數據計數和內䆟\n 注意\n如果遇到 no cached mapping for this field\n試著在 Management，Refresh field list\n Dashboard Page 儀表版功能，Kibana 提供多樣視覺化圖表，儀表版可幫助你收集管理這些圖表\nLogs Page 數據功能，顯示匯入的數據\nQuery DSL Elastic 提供了一套查詢語法 DSL (Domain Specific Language)，可透過 RESTful 或 Kibana 的介面來使用，這邊介紹幾個範例\n  Match\n例如查詢 IIS 中，有那些 Request 回應 500\n GET /_search { \u0026quot;query\u0026quot;: { \u0026quot;match\u0026quot;: { \u0026quot;iis.access.response_code\u0026quot;: { \u0026quot;query\u0026quot;: 500, \u0026quot;type\u0026quot;: \u0026quot;phrase\u0026quot; } } } }    Wildcard\n例如查詢 IIS 中，有那些 Request url like */app/\n GET /_search { \u0026quot;query\u0026quot;: { \u0026quot;wildcard\u0026quot;: { \u0026quot;iis.access.url\u0026quot;: \u0026quot;*/app\u0026quot; } } }    Prefix\n例如查詢 IIS 中，url 以 /en/app 開頭的 Request 有那些\n GET /_search { \u0026quot;query\u0026quot;: { \u0026quot;prefix\u0026quot;: { \u0026quot;iis.access.url\u0026quot;: \u0026quot;/en/app\u0026quot; } } }    參考 Elastic 官網\n","description":"介紹 Kibana 個人應用實例","id":8,"section":"posts","tags":["Kibana"],"title":"如何使用 Kibana 分享日誌","uri":"https://reddtsai.github.io/zh/posts/elk_kibana/"},{"content":"版本\n Filebeat 6\n環境 Windows 10  1. 下載 Filebeat Download Filebeat for Windows\n2. 安裝 Filebeat 解壓縮至 C:\\Program Files\\Filebeat，以 admin 角色開啟 PowerShell\n1 2  cd \u0026#39;C:\\Program Files\\Filebeat\u0026#39; .\\install-service-filebeat.ps1   3. 設定 Filebeat 編輯 filebeat.yml，設定 elasticsearch 和 kibana 的位置\n1 2 3 4  output.elasticsearch: hosts: [\u0026#34;localhost:9200\u0026#34;] setup.kibana: host: \u0026#34;localhost:5601\u0026#34;   4. 設定 Filebeat 模組 收集 IIS Log\n編輯 filebeat\\module\\iis\\access\\manifest.yml\n1 2 3  default.paths: default: - C:/inetpub/logs/LogFiles/*/*.log   啟用 iis 模組\n1  .\\filebeat.exe modules enable iis   5. 啟動 Filebeat 服務 1 2  .\\filebeat.exe setup Start-Service filebeat   ","description":"介紹在 Windows 中安裝 Filebeat","id":9,"section":"posts","tags":["Filebeat","Windows"],"title":"Windows 如何安裝 Filebeat","uri":"https://reddtsai.github.io/zh/posts/elk_windowsfilebeat/"},{"content":"版本\n ElastAlert 0.2\n環境 CentOS 7\n安裝需求 python 2.7 python-dev python-pip dependency Package，參考 ElastAlert requirements.txt  1. 安裝 PIP、DEV 確認是否已安裝 python 2.7\n1  python --version   安裝 python-pip\n1 2 3 4 5  sudo yum -y install python-devel sudo yum -y install epel-release sudo yum -y install python-pip pip --version sudo pip install --upgrade pip   2. 安裝 ElastAlert 確認套件，安裝的過程中可能會遇到相依套件的問題，請參考 ElastAlert requirements.txt 中的需求套件清單\n1  pip list   例如，在安裝 blist 套件時，需要安裝 GCC\n1  sudo yum -y install gcc   例如，在更新 requests 套件時，需要強制移除安裝\n1  sudo pip install requests --ignore-installed requests   安裝 ElastAlert\n1  sudo pip install elastalert   3. 設定 ElastAlert 在 ElastAlert 目錄下新增設定檔 config.yaml。以我的環境為例 /usr/lib/python2.7/site-packages/elastalert\n建議複製 ElastAlert config.yaml.example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  # This is the folder that contains the rule yaml files# Any .yaml file will be loaded as a rulerules_folder:/usr/lib/python2.7/site-packages/elastalert/alert_rules# How often ElastAlert will query Elasticsearch# The unit can be anything from weeks to secondsrun_every:# seconds:minutes:1# hours:# ElastAlert will buffer results from the most recent# period of time, in case some log sources are not in real timebuffer_time:minutes:15# The Elasticsearch hostname for metadata writeback# Note that every rule can have its own Elasticsearch hostes_host:elasticsearch.example.com# The Elasticsearch portes_port:9200# elastalert-create-index to set a mappingwriteback_index:elastalert_statusalert_time_limit:days:2  4. 設定 Elasticsearch Client 確認 Elasticsearch Client 的版本和 Elasticsearch 的版本相符。以我的環境為例，需要將 lasticsearch Client 更新至 6.X 版\n1 2 3  pip list sudo pip uninstall elasticsearch sudo pip install \u0026#34;elasticsearch\u0026lt;7\u0026#34;   在 Elasticsearch 增加一個 ElastAlert 的索引\n1  elastalert-create-index   5. 設定通知規則 新增通知規則設定檔 filebeat_frequency.yaml。以我的環境為例 /usr/lib/python2.7/site-packages/elastalert/alert_rules\n這裡以 IIS Log 為例，當 http status != 200 時，發送一個訊息至 Slack\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  es_host:elasticsearch.example.comes_port:9200name:Examplefrequencyruletype:frequencyindex:filebeat-*# (Required, frequency specific)# Alert when this many documents matching the query occur within a timeframenum_events:50# (Required, frequency specific)# num_events must occur within this amount of time to trigger an alerttimeframe:hours:4filter:- query:query_string:query:\u0026#34;NOT iis.access.response_code: 200 AND event.dataset: iis.access\u0026#34;alert:- slack:slack_webhook_url:\u0026#34;http://slack_webhook_url\u0026#34;  測試規則設定檔\n1  elastalert-test-rule alert_rules/filebeat_frequency.yaml   6. 設定 ElastAlert 服務 執行測試\n1  python -m elastalert --verbose --rule alert_rules/filebeat_frequency.yaml   新增服務\n1 2 3 4  sudo mkdir -p /etc/elastalert/rules cd /etc/elastalert/ sudo cp /usr/lib/python2.7/site-packages/elastalert/config.yaml config.yaml sudo cp /usr/lib/python2.7/site-packages/elastalert/alert_rules/filebeat_frequency.yaml rules/filebeat_frequency.yaml   修改 config.yaml\nrules_folder: /etc/elastalert/rules\n新增服務設定檔\n1 2  cd /etc/systemd/system/ sudo vi elastalert.service   elastalert.service\n1 2 3 4 5 6 7 8 9 10 11 12  [Unit] Description=elastalert [Service] Type=simple User=root Group=root Restart=on-failure WorkingDirectory=/usr/lib/python2.7/site-packages/elastalert ExecStart=/usr/bin/elastalert --config /etc/elastalert/config.yaml --rule /etc/elastalert/rules/filebeat_frequency.yaml [Install] WantedBy=multi-user.target   啟動服務\n1 2 3  sudo systemctl enable elastalert.service sudo systemctl start elastalert.service sudo systemctl status elastalert.service   參考 ElastAlert Repo\nElastAlert Doc\n","description":"介紹在 CentOS 中安裝 ElastAlert","id":10,"section":"posts","tags":["ElastAlert","CentOS"],"title":"CentOS 7 如何安裝 ElastAlert","uri":"https://reddtsai.github.io/zh/posts/elk_centoselastalert/"},{"content":"從事軟體工程師的工作十年了，被稱過軟體工程師(PG)、研發工程師(RD)、後端工程師(Backend)、系統設計師(SD)、系統架構師(SA) \u0026hellip;，雖然職稱一直再變，但自己感覺工作內容並無太大的改變，最近剛好看到一篇有趣的文章，是關於軟體開發者的 Roadmap，並跟自己作個比較。\nNowadays Web Developer 今年5G上市了，在這個網路世代，我突然成了 web developer，到底什麼是 web developer？用Kamran Ahmed的圖可看出現今 web developer 大致可分為 backend、frontend及 devops。另外也列出了 web developer 需具備的技能。\nBackend Skill Tree 後端在搞什麼？看完下方 Backend Roadmap 還想當後端工程師嗎？自己也是後端工程，那就透過這張圖來盤點一下自己(看看自己有多爽🤥)。\n以個人經驗將這張 Roadmap 分為以下幾個大項\n Data Transfer\nDNS、FTP、HTTP、TCP、RPC \u0026hellip; Data Storage\nCache、Database、File \u0026hellip; Host\nDomain、OS、Docker、IIS、Nginx、AWS、GCP、Azures \u0026hellip; Programming\nPython、Golang、.NET、Node.js、Git\u0026hellip; Test\nUnit、Intergration Deployment\nCI、CD Other\nLog、Monitor、Elastic  經以上這些項目來盤點自己是不是個後端工師的同時，也用它記錄分享一些實例和個人經驗(希望未來能補完🙏🙏🙏)。\n以下是Kamran Ahmed所畫後端工程師的技能樹。\nFrontend Skill Tree 前端在搞什麼？以下是Kamran Ahmed所畫前端工程師的技能樹。\nDevOps Skill Tree 運維在搞什麼？以下是Kamran Ahmed所畫運維工程師的技能樹。\nReference 參考來源\ndeveloper-roadmap by Kamran Ahmed.\n","description":"簡介後端工作和技能","id":11,"section":"posts","tags":["Backend"],"title":"前端？後端？後端工程師搞什麼？","uri":"https://reddtsai.github.io/zh/posts/backend_skill/"},{"content":"歷史 Elastic 是由 Elasticsearch、Logstach 和 Kibana 這三個開源項目所組成，最初是由 Shay 編寫的 Elasticsearch 這個食譜搜尋引擎開始，後來與 Jordan 開發的 Logstach 和 Rashid 開發的 Kibana 共同合作。隨後推出一些商業服務並成立 Elastic 這個品牌。\nElasticsearch Elasticsearch 是個搜尋分析尋引擎，能夠集中儲存數據和分散運作，使用 RESTful 方式提供服務。\nLogstach Logstach 是個數據處理工具，將不同來源的資料轉化、解析或加密，然後將數據發送至指定的儲存體。\nKibana Kibana 為 Elastic 的介面(UI)，可用來管理配置 Elastic，或透過 DSL、SQL 查詢語法，將 Elasticsearch 數據分享。\n參考來源 Elastic 官網\n下篇文章會介紹如何利用 Elastic 處理日誌\n","description":"介紹 Elastic 個人應用實例","id":12,"section":"posts","tags":["Elastic"],"title":"Elastic 簡介","uri":"https://reddtsai.github.io/zh/posts/elk/"},{"content":"當你面對數個虛擬機、資料庫、成百的服務、應用程式生成的日誌，你需要一個能處理這巨量負雜日誌的產品，這裡介紹 Elastic 這個產品來協助你，必免自己造輪子。將由下圖的內容來說明，如何使用 Elastic 處理日誌你的日誌。\n日誌收集 首先是如何收集匯整你的日誌？例如你有 IIS、NGINX、MySQL、APP 多種不同類型的日誌，你需要將它們收集起來存放，這裡會使用 FileBeat 和 Logstash 來收集。\n FileBeat 是匯整轉發日誌工具，可使用它內建模組或自訂格式來收集日誌，並將收集來的數據解析發送到 Logstash 或 Elasticsearch 儲存。\n 範例如何使用 Filebeat 收集日誌\n  Logstash 是接收轉發日誌中介服務，從過濾器接收不同形式的來源，透過建構結構來分析轉換成通用格式，再輸出到 Elasticsearch 或其它儲存設備。\n日誌存儲 接下來透過 Elasticsearch 來儲存收集來的資料。\n Elasticsearch 是一個分散式、RESTful 風格的搜尋和數據分析引擎，它是 Elastic 的核心，很像資料庫提供搜索和儲存。\n 範例CentOS 7 如何安裝 Elasticsearch\n 日誌分析 Elastc 提供一個強大的 UI 介面 Kibana，它能協助你分析 視覺化、分享收集來的數據。\n Kibana 是個強大的 UI，透過網頁呈現，提供多種儀表皮和圖表來分享數據。\n 範例如何使用 Kibana 分享日誌\n 日誌監控 最後，Elastc 也提供數據、效能監控服務，這部分屬於白金服務需要付費，也有一些替代方，例如 ElastAlert、Sentinl。\n 範例CentOS 7 如何安裝 ElastAlert\n","description":"介紹 Elastic 個人應用實例","id":13,"section":"posts","tags":["Elastic"],"title":"如何利用 Elastic 處理日誌","uri":"https://reddtsai.github.io/zh/posts/elk_logging/"},{"content":"Filebeat 是個檔案分析工具，最常用來收集日誌檔，收集的過程分為\n 收集數據 (讀取日誌) 解析數據\n常見的日誌格式(IIS、NGINX、MySQL)大多可透過 Filebeat 內建模組來解析，也可透過新增模組來客製格式，以下會說明該如何新增或設定 Filebeat 模組。 傳送數據 (Logstash 或 Elasticsearch 儲存)   版本\n Filebeat 6\n安裝請參考下一篇文章Windows 如何安裝 Filebeat   設定模組 Filebeat 提供多樣模組來收集常見的日誌，這邊以 IIS 日誌為例，說明如何設定模組。\n  設定日誌路徑\n編輯 [Windows 安裝路徑]\\filebeat\\module\\iis\\access\\manifest.yml\n #加入 IIS 日誌路徑 default.paths: default: - C:/inetpub/logs/LogFiles/*/*.log    啟用模組\n開啟 IIS 模組，在 PowerShell 執行下方命令\n cd [Windows 安裝路徑] .\\filebeat.exe modules enable iis    新增模組 新增一個模組後，可看到所產生的檔案結構，以下方我所建立的 nlog module 為例\nfilebeat\n├ module\n│ ⎩ nlog\n│ ⎩ app\n│ ├ manifest.yaml\n│ ├ config\n│ │ ⎩ fileset.yml\n│ ⎩ ingest\n│ ⎩ pipeline.json\n├ modules.d\n│ ⎩ nlog.yml.disabled\n 新增一個模組需透過 Beats 程式碼來逹成，這裡只會說明新模組需要作那些設定，完整資訊請參考 github Beats repository\n   manifest.yaml\nmanifest 控制檔，設定模組參考位置\n #日誌路徑 var: － name: paths os.windows － C:/log/*.log #template 參考路徑 input: config/fileset.yml #Ingest Pipeline 參考路徑 ingest_pipeline: ingest/pipeline.json    fileset.yml\nfileset 輸入組態檔，設定輸入位置、排除輸入檔案、排除輸入行及多行組合\n #排除 .gz 檔 exclude_files: [\u0026quot;.gz$\u0026quot;]    pipeline.json\nlasticsearch ingest node pipeline configurations\n  modules.yml.disabled\n模組開關\n  測試模組 新增或設定好模組，先由測試確認完後再上線\n  測試設定檔\n.\\filebeat.exe test config -c filebeat.yml\n.\\filebeat.exe test output filebeat.yml\n  執行 Filebeat\n.\\filebeat.exe -e -c filebeat.yml -d \u0026ldquo;*\u0026rdquo;\n 注意\n請先清除前次測試所讀取的記錄，刪除目錄 filebeat\\data\\registry\n   檢查 Ingest \u0026amp; Pipeline\n透過 elasticsearch api 查詢 Ingest \u0026amp; pipeline (例如 IIS 模組 pipeline filebeat-6.7.0-iis-access-default)\ncurl -X GET http://elasticsearch:9200/_cat/indices?v\ncurl -X GET http://elasticsearch:9200/_ingest/pipeline\ncurl -X GET http://elasticsearch:9200/_ingest/pipeline/filebeat-6.7.0-iis-access-default\n 如果測試 pipeline 有問題，需要刪除舊的 pipeline.json\n  curl -X DELETE http://elasticsearch:9200/_ingest/pipeline/filebeat-6.7.0-iis-access-default    確認資料\n開啟 Kibana，透過 Logs 介面，確認是否有顯示 log 資料\n  參考 Elastic 官網\n","description":"透過 Filebeat 收集系統、應用程式 Log","id":14,"section":"posts","tags":["Filebeat"],"title":"如何使用 Filebeat 收集日誌","uri":"https://reddtsai.github.io/zh/posts/elk_iisfilebeat/"},{"content":"版本\n Kibana 6.8\n環境 CentOS 7  1. 安裝 OpenJDK 1 2  sudo yum install java-1.8.0-openjdk-devel java -version   2. 安裝 Elasticsearch 簽章公鑰 1  rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch   3. 安裝 Kibana 建立 Kibana 套件容器設定檔 /etc/yum.repos.d/kibana.repo\n填入套件容器參數\n1 2 3 4 5 6 7 8  [kibana-6.x] name=Kibana repository for 6.x packages baseurl=https://artifacts.elastic.co/packages/6.x/yum gpgcheck=1 gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch enabled=1 autorefresh=1 type=rpm-md   安裝 kibana\n1  sudo yum install kibana   4. 配置 kibana kibana 配置檔 /etc/kibana/kibana.yml\n1 2  elasticsearch.hosts: http://localhost:9200 server.host: 0.0.0.0   5. 設定防火牆和IP 新增\n1 2 3 4 5  sudo firewall-cmd --new-zone=kibana --permanent sudo firewall-cmd --reload sudo firewall-cmd --zone=kibana --add-source=\u0026lt;IP_ADDRESS\u0026gt;/32 --permanent sudo firewall-cmd --zone=kibana --add-port=5601/tcp --permanent sudo firewall-cmd --reload   修改\n1 2  sudo firewall-cmd --zone=kibana --add-source=\u0026lt;IP_ADDRESS\u0026gt; --permanent sudo firewall-cmd --reload   測試\n1 2  sudo firewall-cmd --zone=kibana --list-all sudo netstat -plnt   6. 啟動 kibana 服務 1 2  sudo systemctl enable kibana.service sudo systemctl start kibana.service   測試 kibana\nhttp://localhost:5601\n1  sudo systemctl status kibana.service   也可檢查服務記錄訊息\n1  sudo journalctl --unit kibana --since \u0026#34;20 min ago\u0026#34;   參考 Elastic 官網\n","description":"介紹在 CentOS 中安裝 Kibana","id":15,"section":"posts","tags":["Kibana","CentOS"],"title":"CentOS 7 如何安裝 Kibana","uri":"https://reddtsai.github.io/zh/posts/elk_centoskibana/"},{"content":"版本\n Elasticsearch 6.8\n環境 CentOS 7  1. 安裝 OpenJDK 1 2  sudo yum install java-1.8.0-openjdk-devel java -version   2. 安裝 Elasticsearch 簽章公鑰 1  rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch   3. 安裝 Elasticsearch 建立 Elasticsearch 套件容器設定檔 /etc/yum.repos.d/elasticsearch.repo\n填入套件容器參數\n1 2 3 4 5 6 7 8  [elasticsearch-6.x] name=Elasticsearch repository for 6.x packages baseurl=https://artifacts.elastic.co/packages/6.x/yum gpgcheck=1 gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch enabled=1 autorefresh=1 type=rpm-md   安裝 Elasticsearch\n1  sudo yum install elasticsearch   4. 啟動 Elasticsearch 服務 1 2  sudo systemctl enable elasticsearch.service sudo systemctl start elasticsearch.service   測試 Elasticsearch\n1 2  sudo systemctl status elasticsearch.service curl -X GET http://localhost:9200   也可檢查服務記錄訊息\n1  sudo journalctl --unit elasticsearch --since \u0026#34;20 min ago\u0026#34;   5. 設定防火牆和IP 新增\n1 2 3 4 5  sudo firewall-cmd --new-zone=elasticsearch --permanent sudo firewall-cmd --reload sudo firewall-cmd --zone=elasticsearch --add-source=\u0026lt;IP_ADDRESS\u0026gt;/32 --permanent sudo firewall-cmd --zone=elasticsearch --add-port=9200/tcp --permanent sudo firewall-cmd --reload   修改\n1 2  sudo firewall-cmd --zone=elasticsearch --add-source=\u0026lt;IP_ADDRESS\u0026gt; --permanent sudo firewall-cmd --reload   測試\n1 2  sudo firewall-cmd --zone=kibana --list-all sudo netstat -plnt   6. 配置 Elasticsearch Elasticsearch 配置檔 /etc/elasticsearch/elasticsearch.yml\nElasticsearch JVM 配置檔 /etc/elasticsearch/jvm.options\n✳︎記憶體配置不可小放實體記憶體50%\n1 2 3  -Xms2g -Xmx2g network.host: 0.0.0.0   參考 Elastic 官網\n參考官方說明\n","description":"介紹在 CentOS 中安裝 Elasticsearch","id":16,"section":"posts","tags":["Elasticsearch","CentOS"],"title":"CentOS 7 如何安裝 Elasticsearch","uri":"https://reddtsai.github.io/zh/posts/elk_centoselastic/"}]